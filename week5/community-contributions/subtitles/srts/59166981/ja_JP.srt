WEBVTT

00:00.980 --> 00:04.040
第2週5日目へようこそ｡ 

00:04.070 --> 00:09.050
多くのことがまとまりつつある第2週の最終日｡ 

00:09.050 --> 00:18.620
今日は本当に､ 本当に楽しい日になりそうだから｡

00:18.620 --> 00:21.530
これに参加するのが楽しみだ｡ 

00:21.890 --> 00:24.410
2週目の大きな締めくくりだ｡ 

00:24.740 --> 00:27.800
繰り返しになるが､ 私はあなたに何ができるかを言い続けるつもりだ｡ 

00:27.800 --> 00:32.840
自分のスキルアップを祝うことはとても重要だと思う｡ 

00:32.840 --> 00:39.800
フロンティアAPIに対してコーディングし､ AIアシスタントを構築し､ 専門知識を与えるツールを追加することができる｡

00:39.830 --> 00:42.440
今日はエージェントを紹介しよう｡ 

00:42.440 --> 00:48.650
私たちは､ エージェントがより高度な逐次的活動を行う方法について話します｡ 

00:48.650 --> 00:56.450
そして､ エージェントやツールを使ってマルチモーダルAIアシスタントを作るという､ とても楽しいこともやっています｡ 

00:57.620 --> 00:59.390
では､ エージェントとは何なのか？

00:59.720 --> 01:01.190
エージェントと言うべきだろう｡ 

01:01.220 --> 01:02.390
エージェントI｡ 

01:02.420 --> 01:02.900
エージェントだ｡ 

01:03.530 --> 01:07.790
これは､ 人々がさまざまな文脈で使うことができる包括的な用語のひとつである｡ 

01:07.790 --> 01:12.140
だから､ それは人によって意味が違うことのひとつなんだ｡ 

01:12.140 --> 01:17.660
しかし､ 一般的に言えば､ 多くの場合､ 人々は自律的なソフトウェア・エンティティについて話している｡ 

01:17.660 --> 01:25.640
入力プロンプトを受けてテキストを生成するという意味だけでなく､ タスクを実行することもできる｡ 

01:25.820 --> 01:27.530
うーん､ 典型的な特徴だね｡ 

01:27.530 --> 01:28.700
彼らが自律的だとしよう｡ 

01:28.700 --> 01:33.740
彼らはある種の主体性を持っていて､ 目標志向で､ 何かしらの目的を持っていて､

01:33.740 --> 01:37.520
タスクが具体的なのだ｡

01:37.520 --> 01:42.620
彼らはたいてい､ 何か一つのことに特化している｡ 

01:43.010 --> 01:48.230
一般的には､ エージェントフレームワークと呼ばれるものの一部として設計され､

01:48.230 --> 01:56.450
エージェントがより複雑な問題を解決するために相互作用できる環境のようなものです｡

01:56.450 --> 02:00.020
だから､ 人間に対する一種のリクエスト・レスポンスとは違うんだ｡ 

02:00.020 --> 02:06.150
しかし､ このような環境では､ 従来のソフトウェアとllmsを組み合わせた複数のソフトウェアエージェントが､

02:06.150 --> 02:12.690
タスクを遂行するために相互作用することが想像できる｡

02:12.690 --> 02:19.770
期待される機能としては､ 単なるリクエスト・レスポンスにとどまらないメモリーや永続性を持つ能力､

02:19.770 --> 02:30.750
ある種の意思決定やオーケストレーションができる能力､ プランニング能力などがある｡

02:30.930 --> 02:36.240
そして､ それはただ単に､ 環境に組み込まれたプランニングの問題であることもある｡ 

02:36.240 --> 02:40.410
企画を担当するLLMがいることもある｡ 

02:40.410 --> 02:47.400
複雑な問題を､ 他のモデルが処理できるように小さな問題に分解する方法を知っているモデルなのだ｡

02:47.880 --> 02:53.310
そして､ 道具を使うことも遺伝的AIの一例であることが多い｡ 

02:53.310 --> 02:59.370
もちろん､ 皆さんもよくご存知のように､ 私たちはモデルにデータベースへの接続やインターネットへの接続など､

02:59.370 --> 03:10.450
好きなことをさせる機能を与えている｡

03:10.450 --> 03:18.580
これは単なるif文に過ぎないが､ Llmsにこのようなことができるという効果を与えている｡

03:19.960 --> 03:22.540
だから､ これからいくつかやることがある｡ 

03:22.540 --> 03:26.170
簡単に状況を説明しよう｡ 

03:26.200 --> 03:34.390
まず､ マルチモーダルなユースケースに適した､ 画像を生成する機能を構築する｡ 

03:34.390 --> 03:37.990
それができるLLMコールを用意するつもりだ｡ 

03:37.990 --> 03:39.760
そして､ それを実行する機能になる｡ 

03:39.760 --> 03:42.670
そして､ それ自体がエージェントのようなものだと考えることもできる｡ 

03:42.670 --> 03:49.540
これは､ 非常に特殊で専門的な指導を受け､ それを実行できるソフトウェアのようなものだ｡

03:49.540 --> 04:02.240
これは､ Dall-E three､ つまりOpenAIの画像生成モデルの助けを借りて､ コードで作成したアーティストになります｡

04:02.480 --> 04:07.910
そして､ もし屁理屈をこねたいのであれば､ イメージの生成自体はLM的なものではない､

04:07.910 --> 04:09.650
と主張することもできる｡

04:09.680 --> 04:18.380
ええと､ lmは言語モデルのことですが､ 最近では一般的に､ lmsはより広範なgen AI文脈と同じ意味で使われています｡

04:18.380 --> 04:28.100
だから､ 画像生成や他の種類のマルチモーダル生成は､ LMエンジニアのツールキットに含まれると考えがちだ｡

04:29.120 --> 04:36.290
だから､ 私たちはエージェントを作るために､ これらの､ あー､ これらの､ これらの､ これらの､ これらの機能ができるようにするんだ｡

04:36.290 --> 04:52.580
そして､ 画像だけでなく音も追加し､ AIアシスタントに話し方や絵の描き方を教えるエージェントフレームワークを導入する予定です｡

04:52.760 --> 04:55.820
さて､ 前置きはこれくらいにして､ 楽しそうだと思われただろうか｡ 

04:55.850 --> 04:59.060
エキサイティングに聞こえることを願っているよ｡ 

04:59.090 --> 05:00.320
早くやりたいよ｡ 

05:00.320 --> 05:01.700
さあ､ 今すぐ行こう｡ 
