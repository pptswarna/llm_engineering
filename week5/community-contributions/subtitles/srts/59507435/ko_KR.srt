WEBVTT

00:00.290 --> 00:05.120
이제 훈련 프로세스에 필요한 5개의 하이퍼파라미터에 대해 말씀드리죠

00:05.120 --> 00:07.460
이 중 일부는 전에 간단히 얘기한 적이 있죠

00:07.460 --> 00:12.860
하지만 대부분은 생소할 겁니다 이런 종류의 데이터 과학 프로젝트에서 일한 적이

00:12.860 --> 00:13.670
없다면요

00:13.700 --> 00:18.890
첫 번째는 에포치입니다 몇 번 짧게 언급했었죠

00:18.890 --> 00:27.830
epoch는 훈련 과정의 일부로 전체 데이터 세트를 몇 번이나 검토할지를

00:27.830 --> 00:29.300
뜻해요

00:29.300 --> 00:34.370
여러분이 훈련할 때 각각의 훈련 데이터 포인트를 가지고 세트를

00:34.370 --> 00:37.670
한 번 거치면 끝이라고 생각할 수 있죠

00:37.670 --> 00:42.620
하지만 사실 다시 돌아가서 훈련 데이터를 모델과 함께 다시 검토하면 더 많은 마일리지들을 얻을 수 있어요.

00:42.620 --> 00:45.200
Get in get get get it.

00:45.230 --> 00:46.820
왜냐고 궁금하시겠죠

00:46.820 --> 00:50.240
모델이 이미 한 번 봤는데 왜 다시 보려는 거죠?

00:50.240 --> 00:52.520
두 번째에도 같은 데이터를 주나요?

00:52.520 --> 00:58.160
훈련 최적화 과정을 거치면서 이런 점들을 하나씩

00:58.160 --> 01:04.250
짚어 보고 모델이 더 잘 보이게 작은 단계를 밟아요

01:04.250 --> 01:11.490
무게추를 조금씩 바꾸면 다음에는 더 잘 닦일 거예요

01:11.640 --> 01:16.380
훈련 데이터 세트를 검토할 때마다 조금씩 향상될 기회가 있어요 비트 코일, 비트

01:16.380 --> 01:17.700
코일, 비트 코일

01:17.880 --> 01:22.860
비트가 통과하고 나면 모델이 약간 다른 상태가 되겠죠

01:22.950 --> 01:27.930
비트를 다시 봤을 때 더 개선할 수 있어요

01:28.560 --> 01:35.550
여러 단계가 필요한 또 다른 이유가 있습니다 바로 배치 크기인데요

01:35.580 --> 01:43.950
다음 hyperpaameter 배치 사이즈는 종종 하나의 데이터 포인트를 모델의 전방으로 보내 다음

01:43.980 --> 01:49.410
토큰을 예측하고 손실을 계산한 다음 되돌아가 손실된 금액의 단계별을

01:49.410 --> 01:52.380
계산하지 않는다는 것을 의미하죠

01:52.410 --> 01:56.610
모델 내에서 다른 무게에 영향을 받는 건가요?

01:56.610 --> 02:00.540
그런 다음 올바른 방향으로 작은 단계를 밟아 모델을 최적화하는 거죠

02:00.630 --> 02:06.240
동시에 여러 데이터 포인트를 합치는 게 좋을 때도 있어요

02:06.240 --> 02:13.410
4개나 8개, 16개를 골라서 16개 전부를 같이 하는 거죠

02:13.930 --> 02:17.950
그렇게 하는 이유 중 하나는 성능입니다. 모든 것을 빠르게 할 수 있다는 것을 의미하죠. Get

02:17.980 --> 02:18.460
it.

02:18.460 --> 02:19.630
다 같이 하면 돼요

02:19.660 --> 02:23.920
GPU 데이터 포인트가 16개면 좋은 거죠

02:23.950 --> 02:29.830
단계별로 하는 것보다 여러 번에 나눠서 하는 게 더 좋은 이유가

02:29.830 --> 02:30.670
있어요

02:30.760 --> 02:35.920
하지만 기본 이유는 실적 때문이에요

02:36.100 --> 02:44.710
한 가지 시대로 여러 가지 시도를 할 땐 모든 시도를 한 번에 성공하는 게 일반적이죠

02:44.710 --> 02:52.030
즉, 모델은 각 발생기에서 16개의 데이터 포인트를 다른 배치로 보게 되는

02:52.030 --> 02:52.870
것이죠

02:52.870 --> 02:58.660
사실 데이터는 어떤 면에서 각 발생에 따라 다릅니다 발생을 거치면서

02:58.660 --> 03:02.890
다른 데이터 포인트의 샘플을 보기 때문이죠

03:02.890 --> 03:06.250
그래서 다양한 시대가 좋은 거예요

03:06.880 --> 03:13.630
아주 보편적인 기술이 하나 있는데 각 에포크의 끝에서 모델을 저장하는 거예요

03:13.630 --> 03:20.040
여러 신세계를 실행한 후 각 신세계 끝에서 모델이 어떻게 수행했는지 테스트하는

03:20.040 --> 03:27.270
건 흔한 일입니다 그런데 그 모델은 각 신세계에서 더 많이 배울수록 더 좋아지곤 합니다

03:27.270 --> 03:33.570
하지만 지난 시간에 얘기했던 것처럼 모델이 지나치게 충족되는 지점에 도달하면

03:33.570 --> 03:38.070
이 훈련 데이터에 너무 익숙해져서 그 훈련 데이터만을

03:38.070 --> 03:41.220
위해 해결하기 시작하죠

03:41.220 --> 03:48.480
그리고 테스트했을 때 성능이 더 나빠집니다 훈련 데이터 세트 외의 점수는 기대하지 않기

03:48.480 --> 03:49.740
때문이죠

03:49.740 --> 03:54.690
점점 좋아지고 좋아지고 나빠지고 나빠지는 게 보여요

03:54.690 --> 03:57.450
결과는 계속 나빠지기만 하죠 Get it

03:57.450 --> 04:04.410
이 프로그램을 실행하면서 최고의 모델과 결과를 제공한 이포크를 고르면

04:04.410 --> 04:05.550
되죠

04:05.550 --> 04:08.460
훈련의 결과로 생각하는 거죠

04:08.460 --> 04:12.570
그게 미세 튜닝 모델의 버전이고 그걸 앞으로 가져가는 거죠

04:12.570 --> 04:18.990
더 많은 이전화를 실행해 어떤 모델이 최선인지 고르는 테스트가

04:18.990 --> 04:20.490
일반적이죠

04:21.870 --> 04:26.910
다음 비디오에서 이 매개 변수들을 잠시 멈추고 계속할게요
