WEBVTT

00:00.680 --> 00:03.740
というわけで､ Google Colabの旋風ツアーを楽しんでいただけただろうか｡ 

00:03.740 --> 00:08.240
使い方の簡単さをスクリーンショットで紹介しよう｡ 

00:08.570 --> 00:10.760
コードをたくさん入れるだけでいい｡ 

00:10.760 --> 00:16.010
これはもちろん､ ハグ・フェイス・コードである｡ 

00:16.010 --> 00:27.620
この場合､ 私はフラックス・モデルを使用した｡ これは､ ハグする顔のモデルを見ていたとき､ トップ・トレンド・モデルのひとつだったことにお気づきだろうか｡

00:27.620 --> 00:40.460
これはBlack Forestのテキストから画像への生成モデルで､ オープンソースの画像生成モデルの中でも特に強力なもののひとつだ｡

00:40.880 --> 00:47.210
そして私は､ 『Dall-E』のシュールなスタイルでAIコーディングを学ぶ生徒でいっぱいの未来的なクラスでそれを促した｡

00:47.390 --> 00:51.650
ええと､ それで出てきたのがこれです｡ 

00:51.830 --> 01:03.890
Google Colabを使うことで､ クラウド上で高性能GPUをどれだけ早く使えるかを実感していただけると思います｡

01:05.480 --> 01:11.690
そして､ 私たちは......私たちの進捗状況を確認する時間を取る｡ 

01:11.720 --> 01:13.130
準備は整った｡ 

01:13.130 --> 01:17.390
あなたはオープンソースの冒険を始めるのにふさわしい位置にいる｡ 

01:17.510 --> 01:24.200
フロンティアAPIを使ったコーディングやマルチモーダルAIアシスタントの構築など､ すでに自信を持ってできることに加えて､

01:24.230 --> 01:32.060
ハギング・フェイスやグーグルコラボをナビゲートできるようになり､ 行動の準備は整った｡

01:32.090 --> 01:39.950
だから今度オープンソースのモデルを走らせるときは､ ハグフェイスには2つの異なるレベルのAPIがあり､

01:39.950 --> 01:43.820
その意味と内容を理解することになる｡

01:43.820 --> 01:47.750
まず､ パイプラインと呼ばれるものから始めよう｡ 

01:47.750 --> 01:57.080
オープンソースのモデルを使ったテキスト､ 画像､ 音声の生成など､ さまざまなAIタスクにパイプラインを使えるようになる｡

01:57.110 --> 01:58.220
待ちきれないよ｡ 
