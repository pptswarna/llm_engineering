WEBVTT

00:00.590 --> 00:07.130
오늘날의 Lms는 정말 대단한 모험이었습니다 세계

00:07.130 --> 00:15.140
지식이 필요한 문제를 해결했고 지난 시간에 살펴본 성능을 다시

00:15.140 --> 00:18.710
한번 보여드릴게요

00:18.830 --> 00:22.490
사실 무작위 모델로 시작했지만 바보 같았으니 잊어버리기로 하죠

00:22.520 --> 00:28.760
우선 상수 모델로 평균 수치를 예측했어요

00:29.150 --> 00:32.300
더 잘할 수 있었지만 그렇게 많이는 아니었어요

00:32.300 --> 00:37.850
기능 공학 모델을 사용하면 더 나은 기능으로 향상시킬 수 있어요

00:38.060 --> 00:45.470
하지만 제일 좋았던 건 아무 말이나 갖다 붙인 숲속 모델이었어요

00:45.500 --> 00:47.990
벡터라이즈에게 전해요

00:48.050 --> 00:53.690
400차원 벡터가 있는 프롬프트 좀 보세요

00:53.840 --> 00:55.610
그게 우리의 실수를 가져왔죠

00:55.640 --> 01:01.740
설명에 근거한 제품의 예측과 실제 가격 사이의 평균 차이는 400,000개의

01:01.740 --> 01:09.240
예시 데이터 포인트에 대해 훈련된 후의 97달러까지로 줄어들죠

01:09.690 --> 01:14.010
오늘 그 인간을 공개했어요

01:14.010 --> 01:15.810
그게 첫 번째 모델이었어요

01:15.930 --> 01:20.490
참가자는 오차로 127점을 받았어요

01:20.490 --> 01:27.810
그래서 제가 적어도 원시적인 기능 공학보다는 잘 만들 수 있었어요

01:27.810 --> 01:30.270
꾸준한 것보다는 나았네요

01:30.270 --> 01:34.530
제가 상수보다 잘하지 않았다면 전체 결과를 포함하지

01:34.530 --> 01:36.060
않았을 거예요

01:36.360 --> 01:43.470
하지만 다음 클로드는 저보다 훨씬 잘했어요

01:43.470 --> 01:48.390
클로드는 아무 숲이나 숲과 아주 비슷했어요 아주 비슷했죠

01:48.390 --> 01:53.430
다시 한번 명심해야 할 점은 클로드는 훈련 데이터를 보지 않고 이걸 하고 있다는 거죠

01:53.430 --> 01:56.490
순전히 세계 지식에 근거한 거예요

01:56.490 --> 01:58.560
이 제품을 받았을 때요

01:58.600 --> 02:03.550
씁쓸한 개인적인 경험으로 말씀드리자면 정말 어려운 작업이에요

02:04.210 --> 02:13.870
GPT 4 미니는 더 잘해서 80달러까지 낮췄습니다 GPT 4 미니는 더 잘해서

02:13.870 --> 02:17.020
76달러까지 낮췄죠

02:17.020 --> 02:23.620
프론티어 모델과 API를 이용해 문제 해결법을 구축할 수 있습니다

02:23.620 --> 02:27.280
퇴행 문제처럼 보이는 문제도요

02:27.280 --> 02:27.670
아니에요

02:27.670 --> 02:29.410
숫자 문제라고요

02:29.560 --> 02:30.160
아니에요

02:30.190 --> 02:36.820
텍스트만 완성하면 해결될 것 같은 자연적인 소리는 아니에요

02:36.820 --> 02:46.870
하지만 그런 문제에도 불구하고 GPT 4 미니는 임의의 숲 모델을 능가할 수 있습니다 400,000개의

02:46.870 --> 02:52.360
훈련 데이터 포인트가 있는 전통적인 머신 러닝 모델이죠

02:52.360 --> 03:00.130
이런 모델들이 얼마나 강력한지 보여줍니다 다양한 유형의 상업적 문제에 어떻게 적용할

03:00.130 --> 03:01.510
수 있는지도요

03:02.320 --> 03:09.640
하지만 이제 드디어 훈련의 세계로 넘어갈 수 있겠네요

03:09.670 --> 03:16.720
다음 주제는 어떻게 발전시키느냐입니다 개척 시대 모델을 세밀하게 조정해서

03:16.750 --> 03:20.680
훈련 예시를 더 잘 활용하는 거죠

03:20.710 --> 03:22.870
지금까지 없었던 거요

03:22.870 --> 03:25.780
아주 크고 흥미로운 주제죠

03:25.780 --> 03:29.530
다음 주 전에 완성될 거예요

03:29.530 --> 03:36.790
완전히 다른 세계로 가져가서 오픈 소스 모델을 세밀하게 조정해 경쟁할 수 있는지 봅니다

03:36.790 --> 03:42.220
매개 변수가 아주 적은 걸 다루게 될 거라는 걸 염두에 두고요

03:42.220 --> 03:44.350
완전히 다른 세상이죠

03:44.590 --> 03:51.040
전통적인 머신 러닝이나 선구적 모델을 이길 수 있을지 확인해 보죠

03:51.070 --> 03:52.930
기대할 게 많아요

03:53.020 --> 03:57.280
하지만 먼저 내일 다시 만나서 조율을 하죠
