WEBVTT

00:00.560 --> 00:02.330
みなさん､ こんにちは｡ 

00:02.330 --> 00:08.510
あなたがどれほど興奮しているかは私も知っているからだ｡

00:08.540 --> 00:14.930
一晩中､ 私のように走り続け､ その結果を見たがっているに違いない｡ 

00:14.930 --> 00:17.030
でも､ やるべき内容はある｡ 

00:17.060 --> 00:24.050
まず第一に､ データセットのキュレーション､ ベースラインと微調整､ フロンティアモデル､ そして現在実行中のフロンティアモデルを使って､

00:24.050 --> 00:31.550
フロンティアモデルやオープンソースモデルに対してコーディングするなど､ すでに多くのことができる｡

00:31.550 --> 00:37.880
Q ローラ､ ええと､ 今日､ 私は以前､ 2つの弾丸になると言っていたのですが､ トレーニングがどのように機能するかというところから始めて､

00:37.880 --> 00:42.890
ここにもう1つの弾丸を入れました｡

00:42.920 --> 00:48.320
トレーニングのプロセス自体について､ 私はかなり手探り状態だったことに思い当たる｡ 

00:48.320 --> 00:53.330
そしてこの時点で､ ローラを実際に走らせ､ トレーニングし､ 活躍する姿を目の当たりにしたのだから､

00:53.330 --> 00:57.680
少し時間を割いてでもきちんと説明する価値がある｡

00:57.680 --> 00:59.270
だから､ その根拠はある｡ 

00:59.300 --> 01:00.560
もう全部知っているかもしれない｡ 

01:00.560 --> 01:05.300
それは､ この時点であなたが拾ったものかもしれないし､ すでに出会っていたものかもしれない｡ 

01:05.360 --> 01:09.070
いずれにせよ､ それをはっきりさせることは超重要だと思う｡ 

01:09.070 --> 01:11.140
そのために2､ 3分時間を取る｡ 

01:11.260 --> 01:20.110
そして､ あなたが最初にランニングのトレーニングを経験したことは本当に素晴らしいことだと思う｡

01:20.140 --> 01:31.120
その後､ 微調整されたモデルの推論を行い､ 第7週の締めくくりとなる｡

01:31.150 --> 01:32.890
よし､ 始めよう｡ 

01:33.550 --> 01:40.930
そこで､ トレーニングのプロセス､ つまりモデルを改良して､ あるタスクをこなすのがよりうまくなるようにするプロセスには､

01:40.930 --> 01:46.120
4つのステップがあることを説明したい｡

01:46.150 --> 01:53.440
最初のステップはフォワードパスと呼ばれるもので､ これは一種のランニング推論の別名に過ぎない｡

01:53.440 --> 02:01.480
あるデータ､ データセットのあるポイント､ 特定のトレーニングデータがあり､ そのトレーニングプロンプトをニューラルネットワークに通して､

02:01.480 --> 02:08.590
次のトークンの予測を得る｡

02:08.590 --> 02:13.510
これはフォワード・パスと呼ばれるもので､ 入力が入力され､ それを通過し､

02:13.510 --> 02:18.080
出力がトランスの端から飛び出してくると考えているからです｡

02:19.100 --> 02:22.700
それから､ 損失計算と呼ばれるものがある｡ 

02:23.240 --> 02:25.340
これについては後でもう少し詳しく話そう｡ 

02:25.340 --> 02:26.810
でも､ これはオーケーと言っているんだ｡ 

02:26.810 --> 02:31.010
つまり､ ネットワークはこれが出力されると予測したわけだ｡ 

02:31.010 --> 02:35.750
そして実際､ これが本当の意味での次の形なんだ｡ 

02:35.750 --> 02:41.030
そのため､ データには実際に次に何が起こったかを含む実例がある｡ 

02:41.360 --> 02:48.890
そして､ 予想と真実を手に入れた今､ 損失を計算する方法を考え出すことができる｡

02:48.920 --> 02:53.960
精度の逆をいくようなロスのひどさだった｡ 

02:54.590 --> 02:58.340
つまり､ ロスの数字が大きければ大きいほど､ 事態は悪化したということだ｡ 

02:58.700 --> 02:59.750
これがステップ2だ｡ 

02:59.780 --> 03:01.160
損失の計算

03:01.160 --> 03:04.580
ステップ3はバックワードパスと呼ばれる｡ 

03:04.580 --> 03:06.320
これについては､ さまざまな言い方がある｡ 

03:06.350 --> 03:08.900
これはバックプロップ逆伝播と呼ばれる｡ 

03:09.230 --> 03:25.540
そして､ この後方パスでは､ この損失を受け取り､ ニューラルネットワークを振り返って､ このニューラルネットワークの各パラメータをほんの少し微調整したらどうなるだろうかと質問するのです｡

03:25.570 --> 03:29.140
そうすれば､ この損失は大きくなっただろうか､ それとも小さくなっただろうか？

03:29.170 --> 03:31.300
損失はどのように左右されるのか？

03:31.330 --> 03:33.100
この重さはどうですか？

03:33.100 --> 03:35.980
それで損失がどう変わるんだ？

03:36.130 --> 03:39.700
ええと､ この体重によるロスの差は？

03:39.910 --> 03:43.540
その感度をグラデーションと呼ぶんだ｡ 

03:43.570 --> 03:44.290
もちろんだ｡ 

03:44.500 --> 03:47.230
ええと､ 数学では一般的にそうであるように､ "as"､ "as"､ "as"､ "as"｡ 

03:47.410 --> 03:56.020
つまり､ すべてのウエイトの勾配を計算することで､ そのウエイトに少し手を加えただけで､

03:56.020 --> 04:04.240
ロスにどのような影響が出るかを確認するわけだ｡

04:04.570 --> 04:12.970
そして最後に､ 4段階目の最適化ですが､ これは､ 私たちが特定のトレーニングのために､ ウェイト減衰を伴うアダム､

04:12.970 --> 04:19.180
アダムWオプティマイザを選択したことです｡

04:19.210 --> 04:24.280
最適化とは､ よし､ これですべてのグラデーションを計算したぞ､ ということだ｡ 

04:24.400 --> 04:32.270
私たちが今やりたいことは､ 次に同じプロンプトが出されたときに､ もう少しうまくいく可能性が高くなるように､

04:32.270 --> 04:37.850
すべてのウエイトをほんの少し微調整することだ｡

04:37.880 --> 04:39.950
損失はもう少し少ないだろう｡ 

04:40.400 --> 04:46.970
そこで､ ロスが少なくなるように､ 勾配と反対方向に微調整を加える｡

04:47.240 --> 04:52.670
そして､ その小さな一歩は､ 学習率に基づくもので､ どれだけの一歩を踏み出すかは､

04:52.670 --> 04:56.750
学習率の大きさに基づく｡

04:56.840 --> 05:00.290
そして常に､ うまく一般化できるようなやり方でやってみたいものだ｡ 

05:00.290 --> 05:04.610
この入力プロンプトだけを解くことは避けたい｡ 

05:04.610 --> 05:11.090
モデルには､ 将来的にそのようなプロンプトに対応できるよう､ 少しずつ学習していってほしい｡

05:11.450 --> 05:17.660
もちろん､ このプロセスはすべてミニバッチで同時に行われ､

05:17.690 --> 05:27.740
データが1つのエポックになるまで何度も何度も繰り返される｡

05:27.740 --> 05:33.050
その繰り返しがトレーニングというわけだ｡ 

05:33.380 --> 05:38.600
次のビデオでは､ それを図で説明しよう｡ 
