WEBVTT

00:00.050 --> 00:04.520
そして､ Jupyter Labへようこそ！Jupyter Labは僕の大好きな場所のひとつだ｡ 

00:04.670 --> 00:12.350
あなたのスクリーンにJupyter Labが現れたら､ おそらく私たちの8週間分の仕事がすべて入っているルート・ディレクトリにたどり着くだろう｡

00:12.380 --> 00:17.150
もちろん､ ここをダブルクリックすれば1週目に入ることができる｡ 

00:17.150 --> 00:25.100
週目に入りましたので､ 5日目に向かっていただきたいと思います｡

00:25.100 --> 00:30.830
つまり､ 初日にすでに作ったものを土台にして､ ウェブをスクラップし､

00:30.830 --> 00:38.900
その会社について詳しく調べ､ それをパンフレットに使うというビジネス・チャレンジだ｡

00:39.230 --> 00:43.820
もし何か問題があれば､ 私に連絡してください｡ 

00:43.820 --> 00:47.690
でもできれば､ 私が話している間に実行してほしい｡ 

00:47.690 --> 00:49.940
あるいは､ その後にまた戻ってきて､ それをやり直すかもしれない｡ 

00:49.940 --> 00:57.140
そして､ そのコツは､ 何枚かのプリントを追加して､ すべての時点で何が起こっているのかに自信を持っていると自分自身を本当に納得させることだ｡

00:57.140 --> 00:59.120
まずは輸入車から始めようと思う｡ 

00:59.120 --> 01:04.790
Shiftを押しながらEnterを押してインポートを実行することを忘れないでください｡ 

01:04.790 --> 01:10.970
最も可能性が高いのは､ なぜかアクティベートされた環境で動いていないことだ｡ 

01:10.970 --> 01:14.150
JupyterLabはアクティベートされた環境で育った｡ 

01:14.150 --> 01:21.020
Lmms がプロンプトに表示されているか､ ターミナルウィンドウに表示されているか､ Anaconda プロンプトに表示されているかを確認する｡ 

01:21.020 --> 01:26.090
もしそうでなければ､ その部分をもう一度始めて､ 助けが必要ならReadmeを見てください｡ 

01:26.120 --> 01:35.600
状況によっては､ カーネルと呼ばれるPythonプロセスを再起動する必要があるかもしれません｡

01:35.600 --> 01:41.630
カーネル・メニューを開き､ カーネルを再起動してすべてのセルの出力をクリアする｡ 

01:41.630 --> 01:45.230
そして､ またこのノートを始めればいい｡ 

01:45.260 --> 01:47.150
もう一度インポートを実行する｡ 

01:47.570 --> 01:48.560
分かった｡ 

01:48.590 --> 01:51.200
では､ 初期化とセットアップを行おう｡ 

01:51.200 --> 01:53.810
dotのenvファイルを読み込む｡ 

01:53.810 --> 01:56.930
そして､ キーが問題ないことを確認するだけだ｡ 

01:57.110 --> 01:58.730
僕にとってはそうだ｡ 

01:58.730 --> 02:00.830
そして願わくば､ それがあなたにとっても良いものであったことを｡ 

02:00.830 --> 02:05.000
そうでなければ､ トラブルシューティングノートで原因を突き止めよう｡ 

02:05.030 --> 02:12.620
そして､ GPT4の廉価版であるGPT4ミニにモデルを設定している｡

02:12.950 --> 02:15.800
なるほど､ これは見覚えがあるはずだ｡ 

02:15.800 --> 02:20.900
次のセルでは､ 第1週に作成したクラスのウェブサイトを見てみよう｡ 

02:20.900 --> 02:23.660
そして今､ もう少し詳しく見てみよう｡ 

02:23.660 --> 02:26.120
これでプレーするのは2回目だね｡ 

02:26.120 --> 02:31.550
これは､ URLを渡して作成するクラスであることを覚えているだろう｡ 

02:31.550 --> 02:37.100
そのURLを取得するためにrequestsパッケージを使用する｡ 

02:37.400 --> 02:44.570
そしてコンテンツを収集し､ Beautifulsoupという素晴らしい解析パッケージを使って解析する｡ 

02:44.600 --> 02:46.520
ここは何かが違う｡ 

02:46.520 --> 02:52.880
タイトルとコンテンツを解析し､ 不要なものを取り除くだけでなく､

02:52.910 --> 03:02.450
このページで参照されているリンクを集め､ self dot linksと呼ばれるものに集める｡

03:02.450 --> 03:06.170
そこで､ すべてのリンクをそこに保存することにする｡ 

03:07.310 --> 03:15.560
そして､ この小さな線は､ ASTゼロ・ワンのプレビューを通過したところなので､ うまくいけばいいのですが......｡

03:15.590 --> 03:21.590
私たちは､ ああ､ 申し訳ないが､ ああ､ キャンバスを持つGPTの4人に､ この一部を説明してくれるように頼んだ｡ 

03:21.590 --> 03:24.320
だから､ もしかしたら､ これはもうあなたにとってとても身近なことなのかもしれない｡ 

03:25.010 --> 03:30.920
それから､ getcontentsというメソッドを用意して､ このウェブページが何をするのかを記述する｡

03:30.920 --> 03:32.330
では､ それを実行してみよう｡ 

03:32.330 --> 03:38.210
では､ 編集者がウェブサイトを作る前にやったことをもう一度やろう｡ 

03:41.450 --> 03:42.110
エドワード・ダナム

03:42.110 --> 03:46.700
私の素晴らしいウェブサイトをご覧ください｡ 

03:46.730 --> 03:49.670
とても単純な話だけど､ 今の僕らにとってはいいテストだよ｡ 

03:49.670 --> 03:55.460
そして､ 印刷広告ドットゲットコンテンツを印刷しよう｡ 

03:55.640 --> 04:00.680
前回､ タイトルと本文だけを印刷したのを覚えているだろうか？

04:00.770 --> 04:02.150
何が出てくるか見てみよう｡ 

04:02.150 --> 04:03.230
だから今はそうしている｡ 

04:03.230 --> 04:07.940
私たちが手にするのは､ またしてもタイトルであり､ ボディである｡ 

04:07.940 --> 04:10.460
でも､ 他のものも手に入れられるといいね｡ 

04:10.640 --> 04:14.430
あの､ 私たちも......ちょっといいですか？

04:14.460 --> 04:18.900
さて､ Getcontentsの一部として､ タイトルと内容を1つの長い文字列で取得する｡ 

04:18.900 --> 04:25.350
しかし､ もうひとつ見ておきたいのは､ エディター・ドット・リンクとは何かということだ｡ 

04:25.860 --> 04:27.870
何があるのか見てみよう｡ 

04:28.920 --> 04:37.320
そして今､ このリンク変数に､ 私のウェブページにあるすべてのリンクがあることがわかるだろう｡

04:37.440 --> 04:39.720
ええと､ プリントを持っていない方が簡単かもしれない｡ 

04:39.750 --> 04:41.310
こうすればいいんだ｡ 

04:41.340 --> 04:42.510
私たちはそれらをそこにリストアップする｡ 

04:42.510 --> 04:43.620
その方が簡単だろう？

04:43.650 --> 04:44.730
そう､ これだ｡ 

04:44.760 --> 04:47.430
以下は､ 私のウェブページにあるすべてのリンクです｡ 

04:47.430 --> 04:49.800
そしてそれらは現在､ この変数リンクに保存されている｡ 

04:49.830 --> 04:51.750
それがはっきりすればいいのだが｡ 

04:52.200 --> 04:53.220
分かった｡ 

04:53.250 --> 05:00.030
今､ 私たちが会社案内を作っていて､ ウェブページを提供し､ それを使ってより多くの情報を収集させたい場合､

05:00.030 --> 05:06.690
これらのリンクのいくつかをたどって､ どのようにできるかを考えてもらいたい｡

05:06.720 --> 05:08.400
彼らからより多くの情報を集めることができる｡ 

05:08.400 --> 05:11.250
しかし､ これらのリンクのすべてが関連するわけではない｡ 

05:11.250 --> 05:15.120
これらのリンクのいくつかは､ おそらくアナリティクスのタグに含まれているものであろう､

05:15.120 --> 05:17.950
ここにあるもののように､ 赤いニリングになりそうです｡

05:17.950 --> 05:23.140
あるいは､ それとは関係ないようなこともある｡ 

05:23.170 --> 05:33.220
これで､ 販売パンフレットを作成する目的で､ リンクが関連性があるかどうかを把握するコードを書くのは本当に難しくなった｡

05:33.220 --> 05:34.930
それは本当に難しいことだ｡ 

05:34.960 --> 05:43.090
もうひとつは､ スラッシュ・アバウトのようなものへのリンクを､ 完全なURLに置き換えることだ｡

05:43.090 --> 05:47.800
そして､ それはコードを使えば簡単にできるかもしれないが､ それでも決して簡単な作業ではない｡ 

05:47.800 --> 05:56.290
これらのリンクのどれが関連性があるのか､ そしてホストを含む完全なURLは何なのかを把握しようとするコードが組み合わされている｡

05:56.290 --> 06:04.240
もちろん､ GPT4ミニはそういうことをやってくれる｡

06:04.240 --> 06:06.760
それをタスクとして依頼すればいいのだ｡ 

06:06.760 --> 06:12.100
これは､ 微妙で複雑なタスクを手作業でコード化するのではなく､

06:12.100 --> 06:20.350
フロンティア・モデルに委ねて「これをやってくれ｡
