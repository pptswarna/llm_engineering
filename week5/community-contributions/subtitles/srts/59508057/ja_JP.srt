WEBVTT

00:01.100 --> 00:02.660
実は計画を少し変更した｡ 

00:02.660 --> 00:04.910
今日はこれで終わりにする｡ 

00:04.940 --> 00:11.540
この時点で3日目｡ 4日目はウエイトとバイアスの結果を見たり､

00:11.540 --> 00:18.620
トレーニングの進捗状況を調べたりする｡

00:18.860 --> 00:23.150
ええと､ その時点でHuggingfaceのハブのモデルもお見せできます｡ 

00:23.150 --> 00:30.050
それに､ モデルを訓練するのにかかる費用については､ 少し口が滑ったかもしれない｡

00:30.050 --> 00:35.660
このコースの一環として､ ハイパーパラメーター最適化について調べたり､

00:35.660 --> 00:43.370
これを楽しんだりするために､ 本当に多くのお金を費やす必要はない｡

00:43.580 --> 00:49.280
トレーニング・データ・セットを扱いやすいサイズに縮小し､ より賢明なパラメーターを設定することで､

00:49.280 --> 01:02.120
通常仕様のGPUボックスでトレーニングを行い､ このプロジェクトにわずか数セントを費やすことができます｡

01:02.120 --> 01:07.890
私のような完全なオタクになって､ トップエンドのボックスで何本も走り､

01:07.890 --> 01:15.690
5ドルも10ドルも使いたいのなら､ それはそれで必要なことだ｡

01:15.990 --> 01:18.060
でも､ その必要はまったくない｡ 

01:18.810 --> 01:26.580
しかし､ 自分自身を褒め称える時間は絶対に必要だ｡ 

01:26.610 --> 01:28.830
トレーニングランが行われている｡ 

01:28.860 --> 01:32.880
今､ 私が話している間､ それが動いていることを願っている｡ 

01:33.300 --> 01:35.700
そしてあなたは今､ 説明できる立場にいる｡ 

01:35.700 --> 01:38.730
Qローラはオープンソースのモデルを微調整するのにかなり適している｡ 

01:38.730 --> 01:45.360
私がターゲット・モジュールの話をするのにうんざりしているのは確かだが､ 今は､ 学習率や､

01:45.360 --> 01:52.410
ああ､ アルファ､ ああ､ ドロップアウト､ その他オプティマイザーなどさまざまなことを説明するのは､

01:52.410 --> 01:57.330
あなたにとってはごく当たり前のことで､ 複雑なことなんだ｡

01:57.330 --> 02:00.030
これは大きな意味でのスキルアップだ｡ 

02:00.030 --> 02:01.800
おめでとう｡ 

02:01.800 --> 02:03.780
とてつもない進歩だ｡ 

02:03.810 --> 02:08.730
そして次回はウェイトとバイアスに行き､ 何が起きているのか見てみよう｡ 
