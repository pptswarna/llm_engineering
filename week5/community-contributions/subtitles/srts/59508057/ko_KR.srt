WEBVTT

00:01.100 --> 00:02.660
계획이 약간 변경됐어요

00:02.660 --> 00:04.910
오늘은 이만 퇴근할게요

00:04.940 --> 00:11.540
사흘째인데요 나흘째에는 무게와 편향성 결과를 살펴보고 훈련 과정을 검토할

00:11.540 --> 00:16.460
겁니다 비트를 좀 더 달리게 한 다음 진지하게 시간을 들여야

00:16.460 --> 00:18.620
할 것 같아요

00:18.860 --> 00:23.150
어깅페이스 허브에 있는 모델도 보여드릴 수 있어요

00:23.150 --> 00:28.820
그리고 제가 좀 비트를 탄 것 같아요 모델 훈련에 드는 비용에

00:28.850 --> 00:30.050
대해서요

00:30.050 --> 00:35.660
이 코스를 즐기기 위해 많은 돈을 쓰실 필요는 없어요

00:35.660 --> 00:43.370
하이퍼파라미터 최적화를 살펴보기 위해서요 단돈 몇 센트예요

00:43.580 --> 00:49.280
훈련 데이터 세트를 관리하기 쉬운 크기로 줄이는 방법을 간단히

00:49.280 --> 00:56.720
설명하고 싶어요 더 합리적인 매개 변수를 만들어 일반 사양 GPU 박스로 훈련하고

00:56.720 --> 01:02.120
이 프로젝트에 적은 돈을 쓸 수 있도록요

01:02.120 --> 01:07.890
저처럼 완전히 괴짜가 되고 싶다면 필요한 건 그게 다예요. 최고급 박스로

01:07.890 --> 01:15.690
많은 게임을 하고 5달러나 10달러만 쓰면 당신도 당신도 그렇게 될 거예요. 저처럼 말이에요.

01:15.990 --> 01:18.060
그럴 필요 없어요

01:18.810 --> 01:26.580
하지만 앞으로의 일을 축하하려면 잠시 시간을 가져야 해요

01:26.610 --> 01:28.830
훈련 중이에요

01:28.860 --> 01:32.880
제가 말하는 동안에 작동하면 좋겠네요

01:33.300 --> 01:35.700
이제 설명할 수 있는 위치에 있잖아요

01:35.700 --> 01:38.730
오픈 소스 모델을 잘 조정했어요

01:38.730 --> 01:45.360
목표 모듈에 대해 얘기하는 데 질리셨을 거예요 학습율이나 알파,

01:45.360 --> 01:52.410
드롭아웃 같은 걸 설명하는 데도요 최적화 장치 같은 다양한 것들도요 그게

01:52.410 --> 01:57.330
다 여러분에게 제2의 본성이자 복잡한 거죠

01:57.330 --> 02:00.030
이건 정말 큰 활력소예요

02:00.030 --> 02:01.800
축하해요

02:01.800 --> 02:03.780
엄청난 발전이에요

02:03.810 --> 02:08.730
다음 시간에는 무게와 편향으로 가서 어떻게 되는지 보죠
