WEBVTT

00:00.020 --> 00:06.230
そこで､ フロンティア・モデルの世界への探検を､ おそらくほとんどの方がよくご存じであろう､

00:06.230 --> 00:10.550
OpenAIの有名なGPTで遊ぶことから始めようと思う｡

00:10.580 --> 00:16.520
私はプロライセンスを持っているので､ すべてのモデルにアクセスできる｡

00:16.550 --> 00:21.320
ビジネス上の問題がLLMの解決策に適しているかどうか､

00:21.320 --> 00:30.110
どうやって判断すればいいのでしょうか？

00:30.110 --> 00:34.910
このコースで聞かれるような質問なので､ 私たちにとっても有益だ｡ 

00:35.030 --> 00:40.760
もちろん､ 返ってくるのは､ 序論､ 要約､ 問題の本質､ スケーラビリティの必要性など､

00:40.760 --> 00:44.300
非常に注意深く構成され､ 理路整然とした回答だ｡

00:44.300 --> 00:50.480
ここには､ ニュアンス､ 非構造化データ､ 文脈理解､ コスト､ メンテナンスなど､ たくさんの素晴らしい､

00:50.480 --> 00:56.810
理路整然とした指摘があり､ それをうまく要約したものがあるに違いない｡

00:56.810 --> 01:00.110
だから､ これは本当に､ 本当に得意なことなんだ｡ 

01:00.140 --> 01:05.300
私が質問を投げかけると､ たいていは正解するが､ ときどき驚くほど間違える｡ 

01:05.330 --> 01:06.920
今回はどうなるか見てみよう｡ 

01:06.950 --> 01:15.500
この文章にはAという文字が何回出てくるか？

01:16.640 --> 01:18.560
どうなるか見てみよう｡ 

01:18.770 --> 01:20.900
ええと､ それは間違っている｡ 

01:20.900 --> 01:24.170
あなたの文章にはAという文字が5回出てきます｡ 

01:24.410 --> 01:27.380
それが正しいこともあれば､ 間違っていることもある｡ 

01:27.380 --> 01:29.750
難しいんだけどね｡ 

01:29.750 --> 01:33.920
でも､ それが間違っていることにショックを受けるかもしれない｡ 

01:33.920 --> 01:37.610
だからといって､ 私たち人間の方がまだ有利な面もある｡ 

01:37.940 --> 01:42.710
しかし実際は､ この情報がLMに送られる方法に関係しているのだ｡ 

01:42.710 --> 01:45.260
それは､ このトークナイゼーション戦略に関係している｡ 

01:45.260 --> 01:47.180
それについては後で詳しく話す｡ 

01:47.300 --> 01:50.090
しかし､ それが間違っているのは興味深い｡ 

01:50.360 --> 01:55.160
ええと､ もう1つ聞きますが､ これは難しい質問です｡ 

01:55.160 --> 01:59.540
この例えに最もふさわしい言葉を選んでください｡ 

01:59.570 --> 02:03.440
フェザーは鳥にとってのスケールである｡ 

02:03.470 --> 02:05.390
そして､ そこにはいくつかの異なるオプションがある｡ 

02:05.390 --> 02:15.260
というのも､ 魚には鱗があるが､ 爬虫類の鱗ほど区別できる特徴ではないからだ｡

02:15.260 --> 02:20.060
この質問は､ ヴェラムというウェブサイトから得たものだ｡ ヴェラムは､ この種の分析を多く行っている会社で､

02:20.090 --> 02:23.030
後ほど紹介する｡

02:23.270 --> 02:23.840
分かった｡ 

02:23.840 --> 02:25.400
別のモデルに切り替えよう｡ 

02:25.400 --> 02:28.190
ゼロワンのプレビューに切り替えよう｡ 

02:28.220 --> 02:34.490
これはもともとstrawberryというコードネームで呼ばれていたモデルで､ OpenAIの最強モデルであり､

02:34.490 --> 02:40.610
プロ契約者のみが利用できるが､ 最終的には誰でも利用できるようになり､ 今後の展開を予感させる｡

02:40.640 --> 02:45.350
一種の推理の連鎖のようなアプローチで問題を考えていく｡ 

02:45.350 --> 02:55.700
同じ質問をしてみよう｡ この文章にAという文字は何回出てくるだろうか？

02:56.150 --> 02:58.310
もっとうまくやれるかどうか見てみよう｡ 

02:59.690 --> 03:00.980
考えているんだ｡ 

03:02.480 --> 03:04.970
確かに時間がかかるのはわかるだろう｡ 

03:05.000 --> 03:06.710
文字の頻度を数える｡ 

03:06.710 --> 03:07.850
それは期待できそうだ｡ 

03:07.880 --> 03:09.320
よく見てみよう｡ 

03:09.350 --> 03:10.130
知っておいて損はない｡ 

03:10.130 --> 03:12.560
そして､ 正しい答えを導き出す｡ 

03:12.560 --> 03:13.190
その通りだ｡ 

03:13.190 --> 03:16.040
文中にAという文字が4回出てくる｡ 

03:16.040 --> 03:21.320
引用符の中に1回､ "appear "の中に2回｡ 

03:21.320 --> 03:23.090
だから正しい｡ 

03:23.090 --> 03:24.230
とても良い｡ 

03:24.230 --> 03:27.080
ええと､ それからイチゴにも聞いてみよう｡ 

03:27.110 --> 03:33.650
ああ､ このパズルをプレビューして､ このパズルにどうアプローチできるか見てみよう｡ 

03:33.710 --> 03:41.300
適切な例えを選択することは､ 有望な育成でもある｡ 

03:41.300 --> 03:44.510
そして正解は爬虫類｡ 

03:44.510 --> 03:53.960
これで､ GPTの4つのゼロとゼロ・ワンのプレビューから､ 異なるモデル､ 異なる強さのいくつかを感じてもらえるだろう｡
