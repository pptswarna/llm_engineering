WEBVTT

00:00.140 --> 00:02.960
以前､ ヴェラムというAI企業の話をした｡ 

00:03.530 --> 00:08.780
さまざまな質問について話していたとき､

00:08.780 --> 00:25.520
彼らはGPTフォーゼロ・アンド・ゼロワン・プレビュー・ヴェラムがリーダーボードを発表していることを思いついた｡

00:25.520 --> 00:30.650
そして､ 私たちが目の前のタスクに適したLLMを選ぶことについて話すときに見てみましょう異なるリーダーボードの束があります｡

00:30.680 --> 00:39.500
ブックマークしておいて損はないが､ 特にベラムのウェブサイトには便利なことが書いてある｡

00:39.530 --> 00:45.890
そのポップアップによると､ ヴァリマイLLMのリーダーボードのウェブサイトの約半分､

00:45.890 --> 00:54.050
ここにあり､ さまざまなフロンティアモデルのコストとコンテキストウィンドウを比較した表だ｡

00:54.080 --> 00:58.550
特にコストの話をするときに､ 手元にあると本当に便利なんだ｡ 

00:58.580 --> 01:02.390
まず最初に､ 私たちが話したコンテキスト・ウィンドウについて触れておこう｡ 

01:02.390 --> 01:11.910
つまり､ 最大のコンテクストウィンドウを持つモデルはジェミニ1ということになる｡  5フラッシュで､ とんでもないコンテキストウィンドウを持っている｡

01:11.940 --> 01:12.900
とんでもない｡ 

01:12.900 --> 01:15.210
100万トークン｡ 

01:15.210 --> 01:25.350
100万トークンとは､ 通常の英語では約75万語を意味し､ シェイクスピア全集には遠く及ばない｡

01:25.380 --> 01:29.040
思い起こせば､ 私たちはそれが1だと考えていたと思う｡  おそらく200万トークンだろう｡ 

01:29.280 --> 01:39.210
つまり､ 双子座1号を生成し続けるために､ シェイクスピア全集を双子座に1回のプロンプトでほとんど収めることができるのだ｡

01:39.210 --> 01:39.210
5フラッシュ

01:39.210 --> 01:43.560
つまり､ 非常に広いコンテクスト・ウィンドウなのだ｡ 

01:43.590 --> 01:59.250
クロード・シリーズのモデルは20万トークンのコンテクスト・ウィンドウを持ち､ GPTセットは主に12万8000トークンのコンテクスト・ウィンドウを持つ｡

01:59.280 --> 02:11.910
繰り返しになるが､ 1つの会話における一連のプロンプト､ 会話における入力､ 応答､ 次の入力､ 応答､ そして冒頭のシステム・プロンプトのすべてを意味することを覚えておいてほしい｡

02:11.910 --> 02:14.730
それらはすべて､ そのコンテクストウィンドウの中に収まらなければならない｡ 

02:14.730 --> 02:28.770
各トークンは一度にひとつずつ生成され､ それが渡されると､ それ以前のすべての入力と出力を考慮して次のトークンを生成するからだ｡

02:29.250 --> 02:32.280
だから､ それがコンテキスト・ウィンドウに収まらなければならない｡ 

02:32.280 --> 02:36.930
しかし､ 128,000トークンにはそのためのスペースがたくさんある｡ 

02:36.930 --> 02:39.570
10万語くらいかな｡ 

02:39.780 --> 02:44.670
これがコンテキスト・ウィンドウのサイズの見方だ｡ 

02:44.670 --> 02:48.480
そして今､ 私たちはその代償を感じている｡ 

02:48.480 --> 03:01.140
そして､ 一見したところ､ クロード3のようなものを取れば､ これは決して激安には見えないと思うかもしれない｡

03:01.140 --> 03:01.140
5ソネットは､

03:01.170 --> 03:01.770
私が地球上で最もパワフルなLLMで頻繁に使っているものだ｡

03:01.770 --> 03:10.410
たいていの尺度では､ そのコストは入力トークン1個につき3ドル､ 出力トークン1個につき15ドルであることがわかるだろう｡ 

03:10.440 --> 03:15.760
かなり高く聞こえるが､ そうではなく､ インプット・トークン1つにつき3ドルではないからだ｡ 

03:15.760 --> 03:21.580
100万投入トークンあたり3ドルだ｡ 

03:21.580 --> 03:29.200
つまり､ 入力プロンプトにシェイクスピア全集と入力すれば､ 3ドルより少し高い金額を支払うことになる｡

03:29.200 --> 03:34.570
だから､ これらの数字には意味があり､ 注意しなければならない現実の数字であること､

03:34.570 --> 03:41.290
そして､ それぞれのダッシュボードを表示し､ APIコストを注意深く監視することができることを伝えたい｡

03:41.320 --> 03:46.690
通常､ このコースでやることは､ 短いビジネス質問をし､ 物事を要約し､

03:46.690 --> 03:51.160
素早く結論を導き出そうとすることだ｡

03:51.220 --> 03:58.720
ほとんどの場合､ 1セント未満､ 端数ドル未満で済むことがわかるだろう｡

03:58.750 --> 04:08.140
最もよく使うモデルはGPT4ミニで､ コストは0ドルだ｡  100万投入トークンあたり15ドル､

04:08.170 --> 04:12.910
0ドル｡ 100万出力トークンあたり60ドル｡ 

04:12.910 --> 04:19.060
また､ これらは大規模なモデルであり､ これらを実行し､

04:19.060 --> 04:31.780
私たちが得られるような質の高い結果を提供するためには､ 多くの計算が必要であることを念頭に置く必要がある｡

04:31.840 --> 04:37.060
これらのAPI費用は､ 状況的に非常に合理的であると私には思える｡ 

04:37.060 --> 04:42.850
これで､ これらの費用がどのようなもので､ どのような意味を持つのか､ 多少なりとも明確になり､ 見通しがつくといいのだが......｡

04:42.850 --> 04:52.570
合計コストは､ 入力トークンのコストにこの数をかけたものと､ 生成された出力トークンのコストの合計となる｡

04:52.570 --> 04:59.890
また､ APIでは､ 生成する出力トークンの最大数を指定することができる｡

05:00.070 --> 05:03.340
ええと､ これで費用の感覚はつかめたと思う｡ 

05:03.340 --> 05:08.170
このページをブックマークして､ いつでも見られるようにしておくといい｡ 

05:08.200 --> 05:11.620
これらのコストをどのように考えるべきか､ もう少し明確にしよう｡ 

05:11.620 --> 05:15.760
そして､ 私が言うように､ それが本当に意味を持つようになるのは､

05:15.790 --> 05:22.600
モデルに1000回コールするようなシステムを構築するときだ｡
