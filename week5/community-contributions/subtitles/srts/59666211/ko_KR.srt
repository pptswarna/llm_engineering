WEBVTT

00:01.490 --> 00:09.980
새 모델을 시도하기 전에 모델에 대해 한 가지 더 알려드리죠 어떻게 되는지 볼 수 있게 메모해두세요

00:09.980 --> 00:14.930
미세 튜닝 모델을 작동하는 동안 여러분도 함께 즐기세요

00:15.140 --> 00:18.230
우린 일정한 모델로 시작했어요

00:18.230 --> 00:21.320
무작위 모델로 시작했지만 그건 이제 Put it로 할 수 있을 것 같아요

00:21.350 --> 00:23.150
그건 바보 같은 짓이었어요

00:23.300 --> 00:29.450
훈련 데이터 세트에서 평균을 추측하는 상수 모델은 결국 146

00:29.450 --> 00:31.070
오류가 되죠

00:31.280 --> 00:35.930
146점보다는 더 잘했으면 좋겠어요

00:35.960 --> 00:38.900
아니면 그냥 계속 만나는 게 나아요

00:38.930 --> 00:44.630
아주 간단한 전통적인 머신 러닝을 기본 기능으로 사용했더니 139개가 나왔어요

00:44.660 --> 00:45.170
기억나요?

00:45.170 --> 00:50.840
무작위의 숲과 더 정교한 알고리즘이 언어를 살펴보고

00:50.840 --> 00:53.900
97개로 줄었길 바라요

00:54.710 --> 00:58.520
이 인간은 56kg으로 형편없었어요

00:58.910 --> 01:00.500
GPT 4요

01:00.530 --> 01:03.940
덩치 큰 친구가 아주 잘했어요

01:03.940 --> 01:18.430
76위와 배스 라마가 3위예요 1번은 훈련받지 않고 4개로 수량화했는데 끔찍한 396달러의 오류를 냈어요

01:18.460 --> 01:23.710
훈련받지 않은 라마를 쓰는 것보다 상수를 쓰는 게 훨씬 나아요

01:23.800 --> 01:26.560
가엾게도 잘 지내지 못했어요

01:26.740 --> 01:31.000
이걸 한 번 더 훑어볼게요 그래야 액자가 잘 나오죠

01:31.030 --> 01:37.060
GPT 4의 중량은 수조 단위라는 걸 기억하세요

01:37.120 --> 01:40.390
GPT 4는 1이었죠 76조 GPT 4요

01:40.630 --> 01:44.380
알려진 바는 없지만 그 이상으로 여겨지죠

01:44.380 --> 01:46.600
무게가 엄청나죠

01:46.630 --> 01:53.530
라마 3요 1기지는 80억 개인데 우린 그걸 4분의 1로 줄였어요

01:53.530 --> 01:57.130
이제 색을 칠해 볼게요

01:57.340 --> 01:57.580
미안해요

01:57.610 --> 02:04.900
로라 어댑터에는 109MB가 들어가는데 거기에 쓸 추가 무게를 더하기 위해서죠

02:04.930 --> 02:11.900
라마레마3요 1베이스지만 여전히 작은 숫자죠 오픈 소스 모델이라

02:11.900 --> 02:13.670
무료로 실행할 수 있어요

02:13.670 --> 02:20.480
이런 얘기를 하는 건 기대를 심어주기 위해서예요 개척지에서 일하는 모델들과 경쟁하는

02:20.480 --> 02:22.610
건 무리한 요구죠

02:22.820 --> 02:27.110
우리가 기존의 머신 러닝보다 더 잘할 수 있을지 살펴봐야 해요

02:27.350 --> 02:28.910
인간보다 더 잘할 수 있을까요?

02:28.940 --> 02:29.150
물론이죠

02:29.150 --> 02:30.470
계속보다 더 잘할 수 있어요?

02:30.470 --> 02:35.090
GPT 4와 우리를 비교하면 어떤 스택이 나올까요?

02:35.210 --> 02:42.590
최전방 모델이죠 GPT 4나 미니와도 나중에 비교할 수

02:42.590 --> 02:43.580
있어요

02:43.880 --> 02:45.800
그게 맥락을 제공하죠

02:45.830 --> 02:46.910
잘 생각해 보세요

02:46.910 --> 02:50.060
앞으로 닥칠 일에 대비해서 숫자를 적어두세요

02:50.060 --> 03:00.500
이제 콜랍으로 가서 가장 강력한 체크포인트를 추론할 때입니다 수직화된 오픈

03:00.500 --> 03:08.380
소스 모델을 훈련한 결과죠 HDP, HDP, HDP
