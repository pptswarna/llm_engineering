WEBVTT

00:01.490 --> 00:09.980
だから､ 新しいモデルを試す前に､ これまでのモデルをもう1度振り返り､ 自分たちがどうするかわかるようにメモしておこう｡

00:09.980 --> 00:14.930
そして､ 私たちが微調整したモデルを走らせている間､ あなたの興奮はそこにある｡ 

00:15.140 --> 00:18.230
まずは一定のモデルから始めた｡ 

00:18.230 --> 00:21.320
実はランダムなモデルから始めたのだが､ それはもう終わりにしよう｡ 

00:21.350 --> 00:23.150
あれはあれでバカバカしい｡ 

00:23.300 --> 00:31.070
つまり､ 訓練データセットから平均値を推測するだけの定数モデルでは､ 146の誤差に終わる｡

00:31.280 --> 00:35.930
146よりもいい結果を出したいと思っている｡ 

00:35.960 --> 00:38.900
そうでなければ､ 定数にこだわる方がいい｡ 

00:38.930 --> 00:44.630
基本的な特徴を持つ､ 非常に単純化された従来の機械学習を使ったところ､ 139の結果が出た｡ 

00:44.660 --> 00:45.170
覚えているかい？

00:45.170 --> 00:50.840
まあ､ ランダムフォレストという､ より洗練されたアルゴリズムで､ 言語や単語を調べて､

00:50.840 --> 00:53.900
97まで下がればいいんだけどね｡

00:54.710 --> 00:58.520
この人間は127で下手な仕事をした｡ 

00:58.910 --> 01:00.500
GPT4だね｡ 

01:00.530 --> 01:03.940
ああ､ あの大男は実によくやったよ｡ 

01:03.940 --> 01:18.430
76歳､ バス・ラマ3世｡  1､ 未訓練､ 4ビットに量子化され､ 396ドルのエラーを出した｡ 

01:18.460 --> 01:23.710
訓練されていないラマを使うより､ 一定にこだわる方がずっといい｡ 

01:23.800 --> 01:26.560
可哀想に､ 特にうまくはなかった｡ 

01:26.740 --> 01:31.000
だから､ もう1度､ このことを確認する｡ 

01:31.030 --> 01:37.060
問題は､ GPT4は何兆ものウェイトを持つモデルだということだ｡ 

01:37.120 --> 01:40.390
GPT4は1だった｡  76兆GPT 4

01:40.630 --> 01:44.380
定かではないが､ それ以上のものだと考えられている｡ 

01:44.380 --> 01:46.600
だからウェイトの数は膨大だ｡ 

01:46.630 --> 01:53.530
ラマ 3. 1つのベースには80億の重みがあり､ 我々はそれを4ビットにまで減らした｡ 

01:53.530 --> 01:57.130
そして､ 私たちの色を使った｡ 

01:57.340 --> 01:57.580
申し訳ない｡ 

01:57.610 --> 02:04.900
私たちのローラ・アダプターは109MBの価値があり､ 適応するために使用できる余分なウェイトを置くことができる｡ 

02:04.930 --> 02:13.670
ラマのレンマ3｡  1ベースだが､ これはまだ少数であり､ 明らかにこれはオープンソースモデルである｡

02:13.670 --> 02:22.610
だから､ フロンティアでこのようなモデルと競争しようとするのは､ 明らかに大変なことだと期待させるために､ このようなことを言っているんだ｡

02:22.820 --> 02:27.110
注目しなければならないのは､ 従来の機械学習よりもうまくやれるかどうかということだ｡ 

02:27.350 --> 02:28.910
人間以上のことができるだろうか？

02:28.940 --> 02:29.150
確かに｡ 

02:29.150 --> 02:30.470
一定以上の結果を残せるか？

02:30.470 --> 02:35.090
また､ GPTの4人と比較した場合､ 私たちはどうなのだろうか？

02:35.210 --> 02:43.580
だから､ リーディング・フロンティア・モデルは､ GPT4やミニとも比較できる｡

02:43.880 --> 02:45.800
だから､ その背景がわかる｡ 

02:45.830 --> 02:46.910
このことを心に留めておいてほしい｡ 

02:46.910 --> 02:50.060
これから起こることに備えて､ 数字を書き留めておくのもいいかもしれない｡ 

02:50.060 --> 03:00.500
そして､ 私たちはColabに向かい､ 私たち自身の縦割りに特化した､ えー､ オープンソースモデルのトレーニングから得られた､

03:00.500 --> 03:08.380
ベストで最強のチェックポイントで推論を実行する時なのだ｡
