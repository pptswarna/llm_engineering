WEBVTT

00:00.920 --> 00:06.260
이번에도 시상대에 올랐습니다 모델들의 퍼포먼스를 감상해 보죠

00:06.260 --> 00:12.050
이미 답을 아시지만 그래도 한번 보고 웃어야겠어요

00:12.320 --> 00:18.590
먼저 훈련 데이터 세트에서 평균 값을 추측하는 상수 모델을 살펴보죠

00:18.950 --> 00:22.880
그 숫자를 보면 146이었죠

00:23.000 --> 00:26.150
확실히 더 낮아 보여요

00:26.150 --> 00:28.070
이유는 아실 거예요

00:28.370 --> 00:34.100
그리고 전통적인 머신 러닝 모델을 살펴봤는데 평균을 넘을 수 있었어요 그러길

00:34.100 --> 00:36.260
바라지만 대다수는 아니었죠

00:36.470 --> 00:42.050
무작위 숲 접근법을 살펴봤는데 97년에 나온 전통적인 머신

00:42.050 --> 00:44.510
러닝 접근법 중 최고였어요

00:44.510 --> 00:51.140
인간과 비교해 보니 인간은 단순한 기본 특징을 이길 수 있었지만

00:51.140 --> 00:53.870
숲의 모델에 지고 말았죠

00:54.140 --> 01:00.290
GPT 40은 다양한 프런티어 모델 중 최고였어요 인간을

01:00.290 --> 01:04.610
76배나 능가하며 완벽하게 해냈죠

01:04.820 --> 01:15.310
오늘은 미세하게 조율된 베이스 라마 3을 살펴봤어요 180억 매개 변수가 4분의 1로 양분화됐어요

01:15.430 --> 01:21.190
396도라는 걸 확인했는데 정말 심각했어요

01:21.280 --> 01:29.950
8비트로 양자화했을 때가 약간 더 나았습니다 오차가 301달러로 늘었죠

01:30.160 --> 01:36.550
라마 3은 시작이 안 좋네요 1점이지만 도전이 시작됐으니 어떤 면에선

01:36.550 --> 01:37.780
신나죠

01:37.870 --> 01:45.640
이 모델을 가지고 어떻게 개선할지 시험해 볼 거예요

01:45.640 --> 01:53.410
저희 목표는 GPT 4 같은 모델과 경쟁하는 겁니다 매개 변수가 수조 개나

01:53.410 --> 01:54.460
되죠

01:54.460 --> 01:59.530
이 특정 작업에서 경쟁력을 갖추고 무료 오픈 소스 모델로

01:59.530 --> 02:04.240
작업할 수 있다면 우린 대단한 걸 이룬 거죠

02:04.240 --> 02:05.080
네

02:05.110 --> 02:11.690
요약하자면, 이 시점에서 여러분은 80%의 여정을 마쳤는데

02:11.690 --> 02:14.120
정말 대단한 거예요

02:14.120 --> 02:15.260
정말 기뻐요

02:15.290 --> 02:16.190
계속 물고 늘어져요

02:16.190 --> 02:17.660
와줘서 정말 기뻐요

02:17.660 --> 02:20.690
아직 20%가 안 왔어요

02:20.690 --> 02:21.740
최고예요

02:21.740 --> 02:23.060
그게 최고죠

02:23.090 --> 02:25.820
가장 맛있는 콘텐츠는 다음에 나올 거예요

02:25.820 --> 02:27.860
이 모델을 훈련할 때요

02:27.860 --> 02:32.540
다음 주 결승전에선 모든 걸 합쳤어요 TUZ TUZ TOZ TUZ

02:32.540 --> 02:35.210
점점 더 커질 거예요

02:35.210 --> 02:37.160
Get it, get it, get it, get it, get 갈수록 더 좋아질 거예요

02:37.160 --> 02:38.300
조금만 참아요

02:38.330 --> 02:40.250
좋은 건 다 나올 거예요

02:40.250 --> 02:44.870
다음 시간에는 hyperperameter를 더 할 거예요

02:44.870 --> 02:50.390
하이퍼파라미터는 좀 힘들 수도 있지만 정말 중요한 걸 배우는 비트예요

02:50.390 --> 02:54.530
hyperperameter가 있어요 컨트롤 훈련이죠 설명해 드릴게요

02:54.560 --> 03:00.020
그런 다음 감독자 미세 조정 SFT 트레이너를 설치할 거예요 여기서 모든 게

03:00.020 --> 03:00.830
이뤄지죠

03:00.830 --> 03:03.650
그리고 훈련을 시작할 거예요

03:03.650 --> 03:11.720
여러분은 독자적인 대형 언어 모델을 훈련하게 될 겁니다 라마 3을 기반으로요 1단계 모델이죠

03:11.720 --> 03:15.320
다음 세션에서 그걸 할 거예요

03:15.320 --> 03:17.210
그럼 거기서 봐요
