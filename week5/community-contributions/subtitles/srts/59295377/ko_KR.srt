WEBVTT

00:00.770 --> 00:06.050
더 고급 지표로 넘어가기 전에 친칠라 스케일링 법칙을

00:06.050 --> 00:12.410
언급하고 싶습니다 구글 딥마인드 팀이 만든 멋진 이름의 법이죠 친칠라

00:12.410 --> 00:15.200
모델 이름을 따서요

00:15.590 --> 00:22.640
모델에서 필요한 매개 변수의 개수와 신경망의 무게에

00:22.640 --> 00:28.580
관한 거죠 법에 따르면 매개 변수의 개수는

00:28.580 --> 00:35.630
훈련 데이터와 훈련 토큰의 개수에 비례해요

00:35.960 --> 00:42.290
그 말은 모델이 있다고 가정해 봅시다. 예를 들어 80억 개의 매개 변수 모델이 있다고 합시다.

00:42.290 --> 00:47.000
그리고 어느 지점에 도달하면 반환률이 감소하기 시작할 거예요.

00:47.030 --> 00:50.660
훈련 데이터를 추가한다고 모델에 큰 영향을 주진 않아요

00:50.660 --> 00:56.720
그래서 여러분은 이 크기의 모델에 대한 트레이닝 데이터가 적당하다고 느끼죠

00:56.720 --> 00:58.430
좋은 대결이 될 거예요

00:58.430 --> 01:06.170
훈련 데이터를 성공적으로 활용해 이 모델을 최대한의 학습 능력으로 끌어올렸죠

01:06.500 --> 01:08.450
괜찮은 질문일 수도 있어요

01:08.450 --> 01:15.240
매개 변수를 더 추가하고 싶다면 모델에 더 유연하게 학습할 수 있고 더 강력하고 미묘한

01:15.240 --> 01:16.740
차이를 줄 수 있죠

01:16.770 --> 01:20.910
훈련용 데이터가 얼마나 더 필요하죠?

01:20.940 --> 01:26.310
답은 이겁니다. 훈련 데이터를 두 배로 늘린다면 그 시점에서 수익이

01:26.310 --> 01:31.920
감소할 테고 무게는 두 배가 될 겁니다. 80억에서 160억 매개 변수가

01:31.950 --> 01:39.330
필요할 거예요. 훈련 데이터를 두 배로 쓰고 효과적으로 학습하려면요. 결과적으로 더 강력하고

01:39.330 --> 01:42.720
미묘하게 표현되려면요.

01:42.990 --> 01:50.130
훈련 데이터를 효과적으로 흡수하려면 매개 변수가 얼마나 더 필요한지 알 수 있죠

01:50.340 --> 01:58.050
그리고 그 이면에는 정반대의 관계도 있어요

01:58.050 --> 02:02.970
여러분이 80억 모델로 작업했는데 누군가 160억 매개 변수 모델로

02:02.970 --> 02:07.440
업그레이드하고 싶다고 하면 그걸 대신 사용하세요

02:07.650 --> 02:11.820
이렇게 생각할 수 있죠 이런 추가적인 유연성과

02:11.820 --> 02:20.170
예측력을 이용하려면 더 큰 모델에 다이얼과 추를 더 많이 적용해야 한다고요

02:20.440 --> 02:25.270
이를 이용하기 위해 얼마나 더 많은 훈련 데이터가 필요할까요?

02:25.270 --> 02:30.070
그 대답은 훈련 데이터 집합의 두 배가 필요하단 거죠

02:30.070 --> 02:36.220
훈련 토큰과 매개 변수의 관계는 몇 년 전에 제안된 것으로

02:36.250 --> 02:38.920
지금까지도 유효하죠

02:38.920 --> 02:46.330
변압기 구조에서 변압기 규격 법칙이 적용되는 것으로 밝혀졌죠

02:46.330 --> 02:46.990
글쎄요

02:46.990 --> 02:49.780
상황에 따라 행동하는 게 경험에서 나온 법칙이죠

02:50.710 --> 02:51.580
좋아요

02:51.610 --> 02:56.050
이제 벤치마크로 넘어가죠

02:56.050 --> 03:04.630
벤치마크는 사람들이 흔히 말하는 측정 기준입니다 다양한 모델을 재는 데 사용되죠

03:04.660 --> 03:12.670
일련의 테스트가 적용되고 다양한 leaderboard에서 사용됩니다 다양한 LMS의

03:12.670 --> 03:18.400
순위를 매기는 곳이죠 다양한 모델의 장단점을 보는 거예요

03:18.430 --> 03:22.270
이제 다양한 벤치마크 테이블이 있어요

03:22.270 --> 03:28.320
하나씩 살펴보면서 감을 잡을 거예요 get it get it

03:28.350 --> 03:32.850
이런 벤치마크가 뭔지 기억할 필요는 없어요 언제든 찾아보면 되니까요

03:32.850 --> 03:36.810
그런 걸 느끼는 게 도움이 돼요 빨리 돌아오니까요

03:36.810 --> 03:41.940
그러니 집중해서 잘 보고 조사도 좀 하세요

03:41.940 --> 03:42.870
궁금한 게 있으면요

03:42.870 --> 03:47.160
이 숫자들은 나중에 다른 모델을 비교할 때 분석할 때 볼

03:47.160 --> 03:47.940
거예요

03:48.030 --> 03:54.300
첫 번째로 말씀드릴 것은 가장 흔한 벤치마크 7가지입니다 어디서나 볼 수 있죠

03:54.300 --> 04:00.510
첫 번째는 Arc입니다 과학적 추론을 측정하는 척도죠

04:00.510 --> 04:03.030
객관식 문제인 셈이죠

04:03.060 --> 04:11.310
Drop은 언어 이해력 테스트로 텍스트를 보고 정제한 다음 텍스트를 추가하거나

04:11.310 --> 04:14.760
정렬하거나 세는 작업을 하죠

04:14.880 --> 04:21.270
더 어려운 암호화, 긴 컨텍스트 저가 활동의 약자인 헬 스웨그는 상식적

04:21.300 --> 04:23.790
추론 테스트의 일종이에요

04:24.240 --> 04:26.820
MLU는 엄청 유명해요

04:26.820 --> 04:28.860
어디서나 볼 수 있어요

04:28.860 --> 04:35.340
57개 피험자를 추론하는 아주 흔한 측정법이었어요

04:35.800 --> 04:42.760
질문이 얼마나 잘 구성됐는지에 대해 의문이 제기되기도 했어요

04:42.760 --> 04:46.000
효과적인지 의심하는 사람들도 있어요

04:46.030 --> 04:47.680
루, 너무 많이 쓴 것 같아요

04:47.680 --> 04:53.860
나중에 루의 변형 버전이 나오는데 지금은 MLU Pro라고 불리죠

04:54.130 --> 04:55.930
이건 대체된 거예요

04:55.930 --> 05:05.140
진실한 QA는 정확성과 견고성을 요구합니다 특히 적대적인 상황에서 진실을 말하지 말라고

05:05.140 --> 05:07.720
부추기는 모델에서는요

05:08.290 --> 05:19.600
위노그랜드는 모델이 더 혼란스러운 상황에서 모호함을 해결할 수 있다는 걸 시험합니다 GSM

05:19.600 --> 05:27.670
8K 수준의 초등학교 수학은 수학이자 초등학교와 중학교의 단어 문제이기도

05:27.670 --> 05:30.010
하죠

05:30.010 --> 05:35.110
이게 자주 보이는 7가지 공통 벤치마크예요

05:35.200 --> 05:36.760
잘 기억해 두세요

05:36.790 --> 05:38.470
자원부에 있어요

05:38.470 --> 05:42.910
앞으로 이런 걸 많이 보게 될 거예요

05:42.940 --> 05:44.770
이제 알아보실 수 있을 거예요
