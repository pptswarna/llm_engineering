WEBVTT

00:00.740 --> 00:08.690
사후 조사를 하기 전에 순위표부터 간단히 살펴보죠

00:08.690 --> 00:15.710
기억하실 거예요 평균에 기반해 지속 실행을 했을 때 오류가 있었죠 평균 예측

00:15.710 --> 00:18.110
차이가 146였어요

00:18.620 --> 00:22.280
전통적인 머신 러닝 때는 139까지 올라갔어요

00:22.280 --> 00:24.800
랜덤 숲은 97이었어요

00:24.830 --> 00:33.860
참가자 중 특히 한 명은 이름을 밝힐 수 없어요 127달러였죠 GPT 4라고 불리는 미니였는데 처음

00:33.860 --> 00:37.400
실행했을 때 80달러였던 것 같아요

00:37.430 --> 00:43.310
GPT 4는 76이었고 방금 나온 건 91이었어요

00:43.310 --> 00:50.300
아까도 말했지만 이전 주행에서 개선된 점이 있지만 이유가

00:50.300 --> 00:52.580
뭐든 어쩔 수 없죠

00:52.580 --> 00:54.350
결과를 조작할 순 없어요

00:54.350 --> 01:01.130
안타깝게도 우리가 가장 집중하는 사업 지표가 약간 부족합니다 세밀

01:01.160 --> 01:05.670
조정이 잘못된 방향으로 이뤄진 것 같아요

01:05.670 --> 01:07.350
그 얘길 해보죠

01:08.280 --> 01:13.830
정신이 번쩍 드는 순간이었어요 여정에서 중요한 걸 배웠죠

01:14.130 --> 01:17.610
시간이 좀 걸리네요

01:17.640 --> 01:23.670
잠시 생각을 해봐야겠어요 개척지 모델을 세밀하게 조정하는 목표가

01:23.700 --> 01:24.600
뭘까요?

01:24.660 --> 01:32.880
미세 튜닝을 자주 사용하는데 매개 변수가 적은 오픈 소스 모델을 선택해 프런티어

01:32.880 --> 01:39.390
모델에 대적할 수 있도록 데이터 세트에서 훈련할 거예요

01:39.420 --> 01:44.760
하지만 수조 개의 매개 변수가 이미 있고 방대한 데이터 세트를 위해 훈련된

01:44.760 --> 01:48.450
개척자 모델이 있다면 목표가 무엇일까요?

01:48.510 --> 01:53.460
개척 시대 모델을 조정한 다섯 가지 주요 목적이 있어요

01:53.460 --> 01:57.390
오픈AI의 웹사이트에서 가져온 것들이에요.

01:57.420 --> 02:05.460
오픈라이에서는 GPT 같은 기능을 세밀하게 조정하는 훈련을 실시하죠

02:05.730 --> 02:12.960
반응의 스타일이나 톤을 만들고 싶을 때 반응에 빈정거림을

02:12.960 --> 02:16.860
추가하는 예가 되죠

02:16.860 --> 02:23.790
특정 형식의 형식, 구성체를 신뢰할 수 있게 제작하고 싶다면 특정한 스타일,

02:23.790 --> 02:27.120
방법, 구조에 있는 형식이 필요해요

02:27.540 --> 02:34.950
세 번째는 수정입니다 어렵거나 어려운 프롬프트를 따르지 않는 모델이죠

02:34.950 --> 02:40.410
아주 복잡한 걸 요구하는데 Get it은 농담을 이해하지 못해요

02:40.800 --> 02:47.130
첨단 케이스 처리란 때때로 노출되는 결함이 있는 경우죠 그걸 수정하고

02:47.130 --> 02:52.020
새로운 걸 실행해야 하는 모델에서요 Get up

02:52.020 --> 02:57.930
그게 우리가 하려던 일이었어요 새로운 작업이었지만 바로 설명하긴 어려웠죠

02:57.930 --> 03:05.110
오픈AI가 사이트에서 강조하는 게 바로 그겁니다 프롬프트만으로 고칠 수

03:05.110 --> 03:12.340
없는 문제를 해결하려고 노력하죠 프롬프트에서 최대한 많은 작업을 하도록 강력하게

03:12.340 --> 03:18.310
권장합니다 GPT 4, 미니 같은 것들은 대부분 프롬프트만으로

03:18.310 --> 03:23.560
아주 높은 수준의 실행을 얻을 수 있거든요

03:23.920 --> 03:28.960
개척지 모델로서는 그게 핵심이에요

03:29.170 --> 03:37.120
이미 당면한 질문과 프롬프트에서 결과물의 스타일을 명시할 수 있어요

03:37.120 --> 03:43.900
이전 결과를 떠올려 보면 GPT 4 미니는 적절한 구조라는 측면에서 정확하게

03:43.900 --> 03:45.280
반응했죠

03:45.280 --> 03:49.990
모든 사건에서 숫자를 추려내지 못한 적이 없어요

03:49.990 --> 03:54.850
숫자는 항상 오차 범위 내에 제품에 근접해 있었어요

03:54.850 --> 04:01.330
추측이었죠, 그래서 챌린지나 출력 형식을 이해하는 데는 문제가 없었어요

04:01.330 --> 04:09.210
GPT4와 GPT4 미니는 엄청난 규모의 훈련 데이터를 가지고 있습니다

04:09.210 --> 04:17.640
세계 지식이 담겨 있죠 500개의 훈련 예시를 더 제공한다고 세계 지식이

04:17.670 --> 04:21.270
달라질 것 같진 않아요

04:21.960 --> 04:29.460
그리고 사소한 문제가 있어요 전에 말했던 심각한 건망증에 대한

04:29.460 --> 04:35.940
건데요 망각이라는 거예요 때때로 미세한 조율을 더하면

04:35.940 --> 04:41.730
훈련 전에 얻은 깊은 지식이 줄어들기도 하죠

04:41.730 --> 04:45.060
세세한 부분까지 신경 쓰는 게 늘 좋은 건 아니에요

04:45.300 --> 04:50.910
엄청난 망각이 원인이었는지 약간 하락했는지도 모르고 시스템에

04:50.910 --> 04:56.940
소음이 있어서 불운이 따랐는지도 몰라요 시험 세트에서 잘 안 풀린

04:56.940 --> 04:58.500
거죠

04:58.800 --> 05:01.860
하지만 나아진 건 없는 것 같았어요

05:01.860 --> 05:02.970
그게 핵심이에요

05:02.970 --> 05:09.420
제 관점에서 그리고 제가 이해하는 방식과 실험이 보여주는 방식으로 볼 때 필요한

05:09.420 --> 05:15.030
걸 확실히 전달하는 훌륭한 일을 이미 하고 있었기 때문이죠

05:15.030 --> 05:22.590
GPT 4는 이미 많은 사람이 이 점을 잘 이해하고 있었고 그 결과의 수준도 이미 매우 뛰어났죠

05:23.580 --> 05:29.610
하지만 당신이 해야 할 일은 계속 작업하는 거예요

05:29.610 --> 05:35.940
하이퍼파라미터 최적화 혹은 시행착오를 통해 개선하려고 했어요 비트

05:36.120 --> 05:37.350
많이는 아니고요

05:37.350 --> 05:43.320
조금이라도 나아지지 않는다면 정말 충격일 거예요 적어도 이전 비트보다 조금이라도

05:43.320 --> 05:46.650
나아진다면요 get it get it

05:46.650 --> 05:48.270
그게 과제군요

05:48.300 --> 05:54.540
더 많은 것을요 오픈AI는 방대한 데이터 집합을 권장하지

05:54.540 --> 06:02.130
않지만 특히 무료일 때는요 저는 더 큰 데이터 집합을 시도해보고 싶어요

06:02.130 --> 06:04.650
훈련 데이터 집합을 1,000이나 2,000으로 해봐요

06:04.680 --> 06:06.930
다른 시대를 살아볼 수도 있고요

06:06.930 --> 06:10.710
해 봤는데 별 차이 없더라고요 다른 걸 시도해 보려고요

06:10.710 --> 06:13.560
다른 hyperperameter도 있어요

06:13.590 --> 06:15.300
오픈아이 웹사이트에서 찾아보세요

06:15.300 --> 06:18.660
원하면 몇 가지 바꿔볼 수도 있어요

06:18.660 --> 06:21.900
하이퍼파라미터 사전에 넣어 보세요

06:22.260 --> 06:28.410
다양한 훈련 데이터를 입력해 볼 수도 있고 프롬프트를 플레이해 볼 수도

06:28.440 --> 06:29.490
있어요

06:29.520 --> 06:37.140
오픈아이가 웹 사이트에서 강조한 점은 입력을 개선함으로써 가장 많은 주행 거리를 얻을 수

06:37.140 --> 06:38.190
있다는 거죠

06:38.310 --> 06:43.890
데이터 큐레이팅과 프롬프트 수정에서 시간을 좀 들인 부분이죠 하지만 여기서

06:43.890 --> 06:46.440
할 수 있는 건 훨씬 더 많아요

06:46.440 --> 06:48.780
그것도 한번 해 보세요

06:48.780 --> 06:55.230
하이퍼파라미터 최적화를 해야 합니다 프롬프트와 관련된 것을 변경해서 더 잘 할

06:55.260 --> 06:56.820
수 있도록 하세요

06:56.820 --> 06:58.200
다시 한 번 볼까요?

06:58.230 --> 07:01.470
76점 이상을 받아야 해요

07:01.590 --> 07:08.020
그리고 솔직히 말씀드리면 저는 이전 경기에서 76점보다 높은 점수를 받은

07:08.020 --> 07:09.310
적이 있어요

07:09.460 --> 07:16.360
그래서 저는 많은 변화 없이 76편보다 나은 걸 만들 수 있다는 걸 알아요

07:16.390 --> 07:18.520
많이 나아지진 않았지만 나아졌어요

07:18.730 --> 07:21.010
그게 바로 도전 과제죠

07:21.040 --> 07:24.790
그렇게 해요, 어떻게 돼가는지 알려줘요 Get it

07:24.790 --> 07:30.610
최적화된 프롬프트나 하이퍼 매개 변수가 있다면 코드를 푸시해 PR을 하세요

07:30.610 --> 07:36.040
제가 살펴보고 공유할 수 있도록요 어떻게 되는지 보도록 하죠

07:36.370 --> 07:43.480
76점 이상을 받으면 그게 바로 도전 과제의 성적이 되는 거죠

07:45.040 --> 07:46.240
좋아요

07:46.240 --> 07:49.870
이렇게 6주 차 결론이 났네요

07:49.870 --> 07:58.690
당신은 이제 놀랍게도 75%에 달하는 길을 달렸습니다 능숙한 달 착륙 엔지니어로서 인공지능과

07:58.690 --> 08:01.900
달 착륙 공학에 통달했죠

08:02.110 --> 08:04.570
여러분도 저처럼 기뻐해 주시면 좋겠네요

08:04.600 --> 08:10.130
정말 멋진 발전이에요 지금까지 배운 모든 걸 자랑스러워해도 돼요

08:10.190 --> 08:15.920
프런티어 모델의 도움을 받아 텍스트와 코드를 생성하고 얼굴 껴안기 트랜스포머,

08:15.920 --> 08:20.570
라이브러리 랑체 같은 오픈 소스 모델을 사용했죠

08:20.720 --> 08:26.960
최근에는 큐레이터 문제 해결 5단계 전략을 다뤘는데요

08:26.960 --> 08:28.250
큐레이팅 데이터를 많이 만들었어요

08:28.250 --> 08:32.420
하지만 달 착륙선 엔지니어의 삶에는 데이터 수집이 많이 포함되죠

08:32.420 --> 08:37.490
Get it은 요령이에요 가장 중요한 부분이죠

08:37.490 --> 08:42.710
제가 했던 모든 실험에서 데이터 구조를 바꾸는 건 바늘을 움직이는

08:42.710 --> 08:44.810
가장 큰 일이었어요

08:44.900 --> 08:48.950
벌써 많은 실험이 post에 올라가 있어요.

08:49.040 --> 08:51.560
하지만 더 잘할 수 있잖아요

08:52.070 --> 08:55.100
전통적인 머신 러닝을 사용했죠

08:55.160 --> 08:59.660
Get up 기본값이 얼마인지 확인하려고요 우리가 쉽게 이겼던 점수죠

08:59.810 --> 09:04.460
개척 시대 해결책을 내놓았고 이젠 미세한 개척 시대 모델이 됐죠

09:04.460 --> 09:06.660
그래서 결과가 좀 실망스러웠죠

09:06.690 --> 09:07.710
현실적이어야 해요

09:07.890 --> 09:11.520
그럼에도 불구하고 여러분의 프로젝트에 사용할 수 있는 거죠

09:11.520 --> 09:17.760
스타일을 바꾸고 싶다거나 어려운 문제가 발생했을

09:17.760 --> 09:20.730
때 미세 조정이 답이죠

09:20.730 --> 09:22.560
그래도 이제 좋은 레시피가 생겼잖아요

09:22.590 --> 09:25.980
어떻게 하는지 알고 연승하는 것도 봤죠

09:25.980 --> 09:28.980
상태를 확인하고 무게와 편향성을 확인했죠

09:28.980 --> 09:31.290
다 알고 계시잖아요

09:32.490 --> 09:42.450
다음 주엔 새로운 관점으로 여행의 새로운 부분을 시작합니다 오픈 소스

09:42.450 --> 09:44.160
모델로요

09:44.160 --> 09:51.090
오픈 소스 모델을 미세 조정하는 건 개척지 모델을 미세 조정하는 것과 아주 다른

09:51.090 --> 09:52.290
제의예요

09:52.290 --> 09:59.970
우리가 하려는 건 우리가 다루는 큰 모델보다 훨씬 작은 모델이에요

09:59.970 --> 10:02.040
여전히 수십억 개의 매개 변수가 있을 거예요

10:02.040 --> 10:09.300
일반적으로 보면 여전히 큰 모델이지만 GPT4와 GPT4 미니에 있는 수조

10:09.300 --> 10:13.290
개의 매개 변수와 비교할 수는 없어요

10:13.320 --> 10:20.460
오픈 소스 모델을 세밀히 조정하고 로라라는 걸 사용할 거예요 들어본 적 있거나 있을

10:20.460 --> 10:24.480
거예요 제가 몇 번 언급했거든요 하지만 로라의

10:24.480 --> 10:30.810
예시를 본 적도 있을 거예요 로라의 사촌인 로라도 들어봤을 거예요 양자화된

10:30.840 --> 10:32.820
버전의 로라죠

10:32.850 --> 10:37.770
둘 다 연습할 거예요 끝날 때쯤엔 둘 다 알게 될 거예요

10:37.980 --> 10:44.640
다음 세션에서는 기본 모델을 선택할 겁니다 이미 알고 계시겠지만요

10:44.640 --> 10:47.310
하지만 진짜 선택해야 해요

10:47.490 --> 10:53.070
GPT 4와 경쟁할 수 있는 모델이 될 거예요

10:53.340 --> 10:56.280
현재 순위표의 우승자는요?

10:56.280 --> 10:59.220
다음 주 과제는 그거예요

10:59.250 --> 11:03.480
큰 도전이 되겠지만 빨리 시작하고 싶어요

11:03.480 --> 11:05.940
당신도 기다려주지 않으면 좋겠네요

11:05.940 --> 11:07.140
그때 봐요
