WEBVTT

00:00.710 --> 00:02.270
ようこそ皆さん｡ 

00:02.300 --> 00:08.900
だから､ 過去に何度も言ってきたけど､ 今週やこのトピックを始めるのが楽しみなんだ｡ 

00:08.900 --> 00:15.020
というのも､ 私が抱いていた興奮は､ 今日の私の興奮のレベルに比べれば､

00:15.020 --> 00:18.260
ほんのわずかなものだったからだ｡

00:18.260 --> 00:24.530
第6週を迎え､ トレーニングの世界に乗り出すにあたり､ これがすべてだ｡ 

00:24.530 --> 00:25.850
いよいよ現実味を帯びてきた｡ 

00:25.850 --> 00:27.260
心の準備をする｡ 

00:28.160 --> 00:32.900
だから､ ここまでは常に推論と呼ばれるものについて話してきた｡ 

00:32.900 --> 00:43.700
推論とは､ 大量のデータに対して学習させたモデルを､ 入力が与えられたときに次のトークンを予測するために実行時に使用することだ｡

00:43.700 --> 00:47.750
そして､ その推論をより良いものにするために､ さまざまな方法を検討してきた｡ 

00:47.750 --> 00:56.330
これからはモデルそのものを見て､ 実行時や推論時にさらに優れたモデルになるように､ どのようにモデルをトレーニングすればよいかを理解していく｡

00:56.660 --> 00:59.780
そして､ ここからが高度になる｡ 

00:59.780 --> 01:04.270
私たちは､ 華やかではない部分､ つまりデータについてから始める｡ 

01:04.270 --> 01:09.640
また､ データセットを作成することは､ 華やかに聞こえないかもしれないが､ 決して華やかではない｡ 

01:09.640 --> 01:14.170
これは絶対に必要なことであり､ おそらく最も重要な部分のひとつだろう｡ 

01:14.170 --> 01:20.590
そして今日と明日は､ データに深く入り込み､ それを隅々まで理解し､ 視覚化し､ 整理し､

01:20.590 --> 01:27.250
キュレーションし､ 私たちがとても気に入る形にすることに費やすつもりだ｡

01:27.400 --> 01:29.410
それは､ あなたがやらなければならないことなんだ｡ 

01:29.440 --> 01:34.960
また､ このプロジェクトの成功をどのように評価するつもりなのか？

01:34.990 --> 01:38.950
何を達成しようとしているのか､ それができたかどうかをどうやって知るのか｡ 

01:39.970 --> 01:48.520
その前に､ あなたが過ごした8週間､ あなたがどこから来て､ どこへ行こうとしているのかについて少し話しましょう｡

01:48.520 --> 01:58.030
今から6週間前に始めたんだけど､ 君たちが向かっている左側にLMエンジニアリングのマスターがいるんだ｡

01:58.030 --> 01:59.230
右側だ｡ 

01:59.260 --> 02:03.190
週目にはフロンティア・モデルについて話し､ いくつか試してみた｡ 

02:03.190 --> 02:06.420
2週目は複数のAPIを使っていた｡ 

02:06.420 --> 02:10.020
私たちはGradioとMulti-modalityを使ってUIを構築していた｡ 

02:10.050 --> 02:15.540
第3週は､ パイプライン・トークナイザー､ そしてモデルのハグについて研究した｡ 

02:15.540 --> 02:18.360
第4週はモデルの選考だった｡ 

02:18.360 --> 02:23.910
コード生成を使っていたが､ 6万倍速いものを作ったんだ｡ 

02:23.910 --> 02:27.120
コードを6万回も最適化できたのは驚くべきことだ｡ 

02:27.150 --> 02:28.410
第5週

02:28.410 --> 02:33.870
先週はもちろん､ 非常にホットな話題で持ちきりだった｡ 

02:33.870 --> 02:42.840
そして今､ 6週目のフロンティア・モデルを微調整し､ 7週目のトレーニングにたどり着いた｡

02:42.840 --> 02:43.860
またやろう｡ 

02:43.860 --> 02:44.640
だが､ 今は違う｡ 

02:44.640 --> 02:49.320
これからはオープンソースのモデルを扱い､ 基本的には自分たちでモデルを作っていくことになる｡ 

02:49.320 --> 02:52.140
そして､ 第8週がすべての集大成となる｡ 

02:52.350 --> 02:58.320
ということで､ 私たちが現在進めている移行について少しお話ししましょう｡ 

02:58.320 --> 03:01.050
私たちは推論からトレーニングへと移行しつつある｡ 

03:01.050 --> 03:05.490
では､ 私たちが推論に取り組んできたとき､ 何をしてきたかについてお話ししましょう｡ 

03:05.490 --> 03:13.310
我々は､ これらのモデルを実行する際に､ より良いパフォーマンスを発揮できるよう､ さまざまなテクニックを開発してきた｡

03:13.340 --> 03:17.990
私たちはマルチショット・プロンプトを試してみた｡ 

03:17.990 --> 03:24.860
プロンプト・チェイニングは､ 複数の異なるメッセージを送信し､ 互いを重ね合わせ､ その結果を組み合わせることで試した｡

03:24.890 --> 03:32.540
私たちは､ そこまで魔法のようなものではないが､ モデルをコードにコールバックできるようなツールを使ったことがある｡

03:32.840 --> 03:40.040
航空券の値段や違う都市への旅行代金を計算するためだ｡

03:40.460 --> 03:48.860
そして最近では､ より関連性の高いコンテンツのコンテクストをプロンプトに注入するラグに取り組んだ｡ 

03:48.890 --> 03:54.800
つまり､ これらすべてに共通しているのは､ 既存の学習済みモデルを利用し､ それを複数回呼び出したり､

03:54.800 --> 04:02.150
コンテキストを追加したりすることで､ そのモデルが知っていることを最大限に活用する方法を見つけ出すということだ｡

04:02.180 --> 04:06.140
これからはトレーニングに移る｡ 

04:06.170 --> 04:17.680
トレーニングで私たちがやろうとしているのは､ 潜在的には何十億ものパラメータを持つディープ・ニューラル・ネットワークを利用することです｡

04:17.680 --> 04:26.140
どのようにパラメータを微調整し､ 重みを変更し､ データに基づいてわずかに最適化することで､

04:26.500 --> 04:35.800
将来のトークンを予測する能力がますます向上するようにすることができます｡

04:35.800 --> 04:45.640
解決しようとしている問題について､ より深く､ より細かい粒度の理解を徐々に積み上げていくことができる､ よりニュアンスのあるテクニックなのだ｡

04:46.030 --> 04:53.710
今､ 数十億のパラメーターを持つLLMを訓練しようとすると､ かなり高価な提案となる｡ 

04:53.710 --> 05:05.620
フロンティア・ラボはおそらく､ 最高のモデルのトレーニングに1億ドル以上を費やすだろう｡

05:05.620 --> 05:07.900
それに予算外だろう｡ 

05:08.200 --> 05:10.890
だから､ 残念ながらそれは不可能なんだ｡ 

05:10.890 --> 05:14.940
しかし幸運なことに､ 我々は転移学習というものを利用することができた｡ 

05:14.940 --> 05:21.630
そして転移学習は､ すでに訓練されたLM､ つまりすでに大量のデータで事前訓練されたモデルを用いて､

05:21.630 --> 05:29.070
特定のデータセットで訓練を続けることは完全に可能だと言う｡

05:29.070 --> 05:34.710
おそらく､ それは非常に専門的な問題を解決するもので､ すでに蓄積された知識をすべて移し､

05:34.710 --> 05:39.840
その上にさらに知識を加えることができるだろう｡

05:40.110 --> 05:48.750
そうすれば､ 事前に訓練されたモデル空間を利用して､ タスクに合わせてより正確に訓練することができる｡

05:48.750 --> 05:51.240
そしてそのプロセスは微調整として知られている｡ 

05:51.450 --> 05:53.760
うーん､ そのまんま､ そのまんま｡ 

05:53.910 --> 06:00.450
ええと､ もちろん､ その方法として､ Qローラのように過去に私が取り上げたテクニックを使うつもりだ｡

06:00.450 --> 06:04.230
メモリなどの面でも管理しやすいだろう｡ 

06:05.100 --> 06:14.220
それでは､ これから数週間の大半を費やすことになる商業的な問題を紹介しよう｡

06:14.220 --> 06:21.510
例えば､ 電化製品､ コンピューター､ 冷蔵庫､ 洗濯機､

06:21.510 --> 06:27.510
その他家庭用や車用のものなど､ 様々な製品の説明文を受け取り､

06:27.510 --> 06:41.400
説明文だけからその製品の価格を推定できるモデルを構築したいとします｡

06:41.790 --> 06:47.160
ええと､ 今のは......わかりやすくていい問題だね｡ 

06:47.160 --> 06:50.010
結果を測るのはとても簡単だ｡ 

06:50.010 --> 06:56.010
データサイエンティストが手を挙げて､ それはテキストを生成するジェネレーティブAIソリューションのために設計された問題には聞こえない､

06:56.010 --> 07:01.980
と言うかもしれない｡

07:02.010 --> 07:04.890
数字を生み出すモデルが必要なようだ｡ 

07:04.890 --> 07:08.580
一般的に回帰モデルと呼ばれるものの領域だ｡ 

07:08.580 --> 07:13.520
このようなモデルには､ その数字にフィットするようなものがある｡ 

07:13.640 --> 07:14.510
そして､ それは正しい｡ 

07:14.540 --> 07:15.860
それは正しい指摘だ｡ 

07:15.860 --> 07:19.100
一般的には､ どちらかというと退行のような問題だ｡ 

07:19.310 --> 07:23.990
うーん､ でも結局のところ､ 僕らにとってはまだ大きな問題になりそうなんだ｡ 

07:23.990 --> 07:25.460
それにはいくつかの理由がある｡ 

07:25.490 --> 07:32.300
そのうちのひとつは､ フロンティアモデルがこの種の問題を解決するのに優れていることがわかったことだ｡ そもそもフロンティアモデルは､

07:32.330 --> 07:42.140
テキストを生成することだけを目的としていて､ 要約などのタスクやその他のテキスト生成アクティビティを含むことができるようにすることだけを目的としている｡

07:42.140 --> 07:48.380
しかし､ 私たちが発見したように､ モデルにJSONで応答するよう求め､ 情報とともに応答すると､

07:48.530 --> 07:54.410
定量的な結果を返すのに非常に効果的である｡

07:54.470 --> 08:00.170
そして実際､ フロンティアモデルは､ おそらくずっと前に話した創発的知性のおかげで､

08:00.170 --> 08:08.330
従来は回帰モデルの領域だったこの種の問題でさえも､ 非常に効果的になりました｡

08:08.450 --> 08:12.320
だから､ このためにJNIを使うことは絶対に可能だ｡ 

08:12.320 --> 08:20.950
そして実際､ フロンティア・モデルは､ 我々が構築する単純な回帰モデルよりも､ この点で目を見張るほど優れていることがわかるだろう｡

08:21.250 --> 08:25.750
だから､ この空間ではうまくいくことがわかった｡ 

08:25.870 --> 08:31.000
自分たちで模型を作れば､ もっと楽しくなるだろう｡ 

08:31.000 --> 08:32.020
その理由はこうだ｡ 

08:32.260 --> 08:40.000
この問題の素晴らしいところは､ うまくいっているかどうかを測るのがとても簡単だということだ｡

08:40.030 --> 08:46.690
もし､ ある製品を予測し､ その製品の価格がわかれば､ それを投入して製品の出来を見ることができる｡

08:46.720 --> 08:50.650
私たちのモデルが､ その製品の価格を推測する際にどの程度の結果を出すか見てみましょう｡ 

08:50.680 --> 08:57.340
他のテキスト生成の問題は､ 人間にとって理解しやすい方法で測定するのが難しい｡

08:57.370 --> 09:08.050
つまり､ 2つの言語間の翻訳をする場合､ 確かに英語からスペイン語がうまく生成されているかどうかはわかる｡

09:08.050 --> 09:10.360
もちろん採点方法もある｡ 

09:10.360 --> 09:17.760
しかし､ そうなると､ その仕組みや､ 実際にうまくいっているのかどうかなど､ 複雑なことがたくさん出てくる｡

09:17.760 --> 09:26.040
だから､ もっとテキスト生成に関連した問題は他にもたくさんあるんだ｡

09:26.040 --> 09:33.270
例えば､ 商品の説明を実際に書くようなものを作るとかね｡

09:33.270 --> 09:36.420
この値段は､ 測定するのが驚くほど簡単だ｡ 

09:36.420 --> 09:40.920
もし私たちがそれをうまくやっていて､ とても人間的に理解しやすい方法で測定していればね｡ 

09:40.950 --> 09:47.790
複雑なデータサイエンスの指標ではなく､ 誰もが理解できるようなものだ｡

09:47.940 --> 09:51.660
今話した冷蔵庫の値段はどれくらい正確ですか？

09:51.990 --> 09:55.230
私たちはそれを見分けることができるし､ 改善を見ていくことができる｡ 

09:55.230 --> 10:04.320
だから､ そのような理由も含めて､ この挑戦は私たちにとって本当に素晴らしく､

10:04.320 --> 10:12.330
明確に定義された挑戦だと思う｡

10:12.840 --> 10:13.590
分かった｡ 

10:13.590 --> 10:17.370
次回のビデオでは､ データについてお話しします｡ 
