WEBVTT

00:01.490 --> 00:06.830
이제 문제의 일부로 넘어가 보죠. 이 부분은 다른 부분만큼 화려하진

00:06.830 --> 00:12.770
않지만 가장 중요한 부분일 겁니다. 바로 데이터를 찾고 만드는 것이죠.

00:12.770 --> 00:16.850
데이터를 찾고 데이터를 사냥할 수 있는 장소가 많아요

00:16.850 --> 00:19.010
하지만 제일 먼저 가는 곳이잖아요

00:19.040 --> 00:25.640
가장 중요한 건 귀사의 독점 데이터죠

00:25.640 --> 00:31.820
여러분이 해결하려는 문제와 직접 관련이 있으면 좋겠고 미세한

00:31.820 --> 00:34.460
조정에 아주 중요할 거예요

00:34.460 --> 00:41.060
가짜로 만든 랙 프로젝트의 경우 그렇게 했죠

00:41.090 --> 00:47.120
우린 우린 지식 기반 구축에 사용한 회사의 공유 드라이브가 있는 척했죠

00:47.150 --> 00:51.260
사유 데이터를 찾는 예가 바로 그거죠

00:51.260 --> 00:57.740
제 사업인 네뷸라의 경우 독자 모델을 훈련하는 데 쓸 수 있는 재능과 직업,

00:57.740 --> 01:00.800
경력에 대한 정보가 있어요

01:00.950 --> 01:07.790
여러분의 문제에 구체적인 소유 데이터 세트를 찾는 것이 첫 번째

01:07.790 --> 01:09.140
시작이죠

01:09.170 --> 01:15.380
캐글도 있습니다 데이터 과학자를 위한 훌륭한 자원이죠

01:15.740 --> 01:17.600
아마 들어보고 사용하셨겠죠

01:17.630 --> 01:19.160
없으면 가서 봐요

01:19.280 --> 01:22.400
데이터가 정말 많아요

01:22.430 --> 01:29.180
데이터는 오랜 기간 동안 사람들이 캐글에 기여한 거예요

01:29.330 --> 01:32.390
그리고 포옹하는 얼굴도 있죠

01:32.420 --> 01:36.080
저희에겐 정말 멋진 자원이에요

01:36.110 --> 01:39.170
포옹하는 표정도 잠시 후에 보여드릴게요

01:39.740 --> 01:42.290
합성 데이터도 있어요

01:42.290 --> 01:46.640
우리 랙 프로젝트는 진짜 회사의 공유 드라이브를 사용하지 않았어요

01:46.640 --> 01:51.350
LLM을 이용해 합성 데이터를 생성했는데 그건 옵션이죠

01:51.350 --> 01:52.880
물론 장단점이 있죠

01:52.880 --> 01:59.780
프런티어 모델을 사용해 데이터를 얻으려 한다면 프런티어 모델이 데이터를 생성하고 학습하는

01:59.780 --> 02:04.690
것은 말이 안 될 수도 있습니다 하지만 자신만의 모델을 만들거나 더

02:04.690 --> 02:09.130
저렴한 모델을 만들려 한다면 프런티어 모델이 시드를 하게

02:09.160 --> 02:15.400
될 것입니다 프런트엔드 모델을 이용해 데이터를 생성하고 그 데이터를 더 작고 저렴하고

02:15.400 --> 02:19.870
가벼운 모델을 훈련하는 데 사용할 수 있죠

02:19.870 --> 02:24.310
다양한 상황에서 합성 데이터가 말이 되죠

02:25.060 --> 02:31.750
그런 다음 여러분을 위해 데이터 세트를 큐레이팅하는 작업을 하는 전문 회사들이 있다고

02:31.780 --> 02:32.890
말씀드리죠

02:32.920 --> 02:37.390
이 회사를 만난 적이 있어요 예전에 실이라는 이름의 leaderboard를

02:37.390 --> 02:45.940
볼 때였죠 Scale이라는 회사에서 만든 Lms의 비즈니스용 leaderboard예요

02:45.940 --> 02:51.040
비율은 여러분의 문제를 위해 정교한 데이터 세트를 만드는 데 전문이죠

02:51.040 --> 02:53.500
또 다른 장소죠

02:53.680 --> 02:59.650
하지만 우리는 얼굴 안기 게임을 할 거예요 아주 귀중한 데이터고 공동체가 기여한 데이터가

02:59.680 --> 03:04.090
많이 들어 있어요 이 특정 데이터 세트도 포함해서요

03:04.240 --> 03:07.600
수년에 걸친 아마존 리뷰를 긁어모아요

03:07.600 --> 03:09.940
정말 거대하네요

03:09.940 --> 03:11.500
정말 방대한 데이터 세트예요

03:11.500 --> 03:18.580
리뷰를 작성하는 것 외에도 제품과 관련된 메타데이터도 있어요

03:18.850 --> 03:22.870
제품 설명과 가격을 포함해서요

03:22.870 --> 03:28.360
그게 바로 우리가 원하는 거죠 제품 설명과 가격이요

03:28.360 --> 03:33.280
이 데이터 세트에는 그 양이 아주 많아요

03:33.280 --> 03:35.680
그래서 저희에게 완벽하죠

03:35.680 --> 03:37.600
우리가 향할 곳은 여기예요

03:39.370 --> 03:42.640
데이터를 어떻게 파헤칠 건가요?

03:42.640 --> 03:44.530
어떤 단계를 밟나요?

03:44.590 --> 03:48.850
오늘 이 작업 중 일부를 하고 일부는 내일 다듬을 거예요

03:49.000 --> 03:55.900
데이터를 깊이 파고들려면 6단계가 있어요

03:55.900 --> 04:02.380
먼저, 조사할 때 데이터를 이해하는 시기가 있어요 어떤 필드를 가질까요?

04:02.380 --> 04:04.420
데이터가 얼마나 꽉 찼나요?

04:04.420 --> 04:07.090
데이터 품질에 어떤 문제가 있나요?

04:07.180 --> 04:13.180
일반적으로 제가 접근하는 방법은 데이터를 구조로 파싱 하는 겁니다 그럼

04:13.180 --> 04:15.490
처리하기 더 쉬워지죠

04:15.670 --> 04:19.900
더는 가공되지 않은 데이터로 작업하지 않아도 되죠

04:19.900 --> 04:23.350
그 시점에서 일반적으로 개체로 작업하죠

04:23.620 --> 04:33.340
시각화를 하는 건 좋은 일입니다 얼마나 넓고 얼마나 퍼져 있는지 보는 건 중요하죠

04:33.340 --> 04:38.650
제품 가격 같은 걸 생각할 때 가격의 차이는 어느 정도인가요?

04:38.650 --> 04:42.940
분포가 어떤 식으로든 삐뚤어져 있는 게 많은가요?

04:42.940 --> 04:46.360
상상해 보세요 그럼 감이 잘 오겠죠 get it get it

04:46.930 --> 04:49.720
이제 데이터 품질을 더 심도 있게 평가해 보죠

04:49.720 --> 04:53.710
데이터의 한계를 이해해야 해요

04:53.830 --> 05:01.290
이를 통해 어떻게 행동하고 큐레이팅할지 결정하고 이 데이터 세트를 어떻게

05:01.290 --> 05:03.630
만들지 결정하게 되죠

05:03.630 --> 05:12.030
예를 들어 데이터의 4분의 1이 데이터 품질이 나쁘다는 사실이 밝혀진다면 해당 데이터를

05:12.030 --> 05:16.020
아예 제외하기로 할 수도 있죠

05:16.020 --> 05:20.190
샘플이 충분히 있어서 4분의 3에 집중할 수 있다고 생각할 수도 있어요

05:20.190 --> 05:25.770
데이터 집합이 어떤 면에서 매우 불균형하고 훈련의 일부로서

05:25.770 --> 05:31.800
모델이 데이터의 특정 균형만 배울까 봐 걱정된다면 이 시기가 잠재적으로

05:31.800 --> 05:35.160
그 균형을 바로잡을 때죠

05:35.160 --> 05:43.110
큐레이팅은 훈련에 가장 적합한 데이터 세트를 만들어 저장하는 거예요

05:43.110 --> 05:46.200
어깅페이스 허브에 업로드할 거예요

05:46.500 --> 05:50.430
훈련하기 전 마지막 단계죠

05:50.460 --> 05:55.590
이제 새로운 프로젝트를 가지고 처음으로 JupyterLab으로 가서 데이터를

05:55.590 --> 05:58.860
큐레이팅하는 법을 배워볼 거예요. HET

05:58.890 --> 05:59.700
거기서 봐요
