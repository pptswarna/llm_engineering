WEBVTT

00:00.590 --> 00:03.110
6주 차, 3일 차예요

00:03.140 --> 00:09.950
오늘은 여러분의 선호도에 따라 호불호가 갈리는 날이 될 겁니다 하지만

00:09.950 --> 00:12.470
중간은 없을 거예요

00:12.500 --> 00:18.410
멋진 하루가 되거나 끔찍한 하루가 될 겁니다 전통적인 머신 러닝에

00:18.410 --> 00:24.380
관심 있느냐에 따라서요 오늘은 과거로 한 걸음 돌아가 기본적인 머신

00:24.380 --> 00:31.160
러닝을 살펴보고 과거 어떻게 작동했는지 실질적인 예시를 볼 테니까요

00:31.370 --> 00:36.740
그런 소개를 하루만 하면 참을 수 있을 거예요 아주 불쾌한 소개라도요 Put

00:36.740 --> 00:38.270
it's go!

00:38.420 --> 00:45.500
다시 한번 말씀드리면 이미 여러분이 할 수 있는 건 개척 모델과 함께 작업하는 겁니다 도구를 이용한 인공지능

00:45.500 --> 00:51.020
조수 만들기 파이프라인, 토큰라이저 모델로 얼굴 안기 같은 오픈 소스 모델로요

00:51.020 --> 00:55.520
긴 체인을 이용해 래그 파이프라인을 만들 수 있죠

00:55.520 --> 01:01.010
사실, 보셨다시피 긴 체인 없이도 충분히 할 수

01:01.010 --> 01:01.910
있어요

01:01.910 --> 01:06.330
라인 체인을 쓰면 더 빠르지만 헝겊은 특별한 마법이

01:06.360 --> 01:07.140
없어요

01:07.170 --> 01:13.020
그리고 상업적 문제를 해결하는 5단계 전략을 얘기했죠

01:13.020 --> 01:16.140
데이터도 아주 심오하고요

01:16.140 --> 01:18.030
상처가 깊지 않아야 할 텐데요

01:18.120 --> 01:20.430
살아남았길 바라요

01:20.430 --> 01:21.750
데이터로 많은 작업을 했어요

01:21.750 --> 01:23.460
차트를 많이 봤어요

01:23.490 --> 01:29.760
지금쯤이면 아이템 클래스와 아이템 로더에 익숙해졌을 겁니다 여러분이 의도했던

01:29.760 --> 01:31.350
것보다요

01:31.560 --> 01:34.740
하지만 이 시점에선 데이터를 처음부터 다 알아요

01:35.010 --> 01:38.250
오늘은 기준점에 대해 얘기할 거예요

01:38.280 --> 01:41.550
기준 모델이 무엇인지 왜 중요한지 말씀드리겠어요

01:41.550 --> 01:47.790
그런 다음 적어도 저는 기본 모델을 가지고 신나게 놀 겁니다 전통적인 머신

01:47.790 --> 01:54.270
러닝을 연구해 이런 화려한 LM 같은 걸 쓰지 않고도 얼마나 잘 만들어지는지

01:54.270 --> 01:55.920
볼 거예요

01:56.040 --> 02:00.060
내일이 오기 전에 개척지로 향할 거예요

02:00.060 --> 02:04.730
비트코인 기준에 대해 얘기해 보죠

02:04.730 --> 02:11.540
상식적인 문제지만 문제를 해결하려면 단순하게 시작해야죠

02:12.200 --> 02:20.600
특히 데이터 과학의 세계에서 근본적으로 중요한 부분입니다 두 가지

02:20.600 --> 02:22.520
이유가 있어요

02:22.790 --> 02:29.000
확실한 건 일종의 잣대를 제공한다는 거예요 진보를 측정할 때 사용할 수 있죠

02:29.000 --> 02:36.110
단순하고 전통적인 것부터 시작하면 정교한 심층 신경망을 제대로 사용한다는 걸

02:36.110 --> 02:37.190
알 수 있죠

02:37.190 --> 02:43.070
바늘이 움직이고 기준선 없이 훨씬 더 높은 곳에 도달하는 걸 볼 때 알 수

02:43.070 --> 02:48.530
없어요 멋진 결과를 얻는 건지 아니면 좋지 않은 방향으로 작은 발걸음을

02:48.530 --> 02:50.570
내딛는 건지요

02:50.750 --> 02:52.970
이게 그 잣대를 제공하죠

02:53.090 --> 02:57.920
하지만 다른 문제도 있어요 llm이 항상 옳은 해결책은 아니에요

02:57.920 --> 03:03.650
사실 저희가 해결하고자 하는 특정 사업상의 문제는 제품 가격 예측

03:03.650 --> 03:05.100
문제인데요

03:05.100 --> 03:11.220
llms가 올바른 솔루션인지는 잘 알 수 없습니다 왜냐하면 일반적으로

03:11.250 --> 03:20.370
앞서 말했듯이 설명에서 가격과 숫자를 생성하는 것은 더 전통적인 NLP와 선형 회귀처럼 보이기 때문입니다

03:20.370 --> 03:23.970
머신 러닝 분야에 속한 것처럼 느껴지죠

03:24.000 --> 03:25.560
전통적인 머신 러닝이죠

03:25.590 --> 03:29.850
그래서 기준점을 만드는 게 더 중요해요 기준점을 만든 다음에

03:29.850 --> 03:33.600
개척 시대 모델을 써 봐도 더 나을 게 없으니까요

03:33.600 --> 03:38.820
뻔한 거지만 왜 이걸 하는지 설명해주죠

03:39.000 --> 03:43.140
오늘은 어떤 모델을 가지고 놀까요?

03:43.170 --> 03:44.310
하루면 돼요

03:44.310 --> 03:46.860
딱 한 번 하는 거잖아요

03:46.860 --> 03:50.550
이런 모델에 이미 아주 익숙하다면 그럴 가치가 있어요

03:50.550 --> 03:55.710
우리의 상업적 문제에 대한 흥미롭고 간단한 실험이 될 겁니다 처음

03:55.710 --> 04:00.990
보시는 분들을 위해 자세하게 설명하진 않겠지만 어떤 관점인지

04:00.990 --> 04:02.550
잘 아실 거예요

04:02.940 --> 04:06.620
가장 먼저 할 일은 사업상의 문제를 해결하는 거예요

04:06.620 --> 04:09.080
아주 옛날 방식으로 할 거예요

04:09.080 --> 04:11.870
기능 엔지니어링이라고 부르는 걸 할 거예요

04:11.870 --> 04:18.350
데이터를 이해하고 가격에 영향을 줄 수 있는 중요한 요인이

04:18.350 --> 04:21.530
무엇인지 생각해 보는 거죠

04:21.530 --> 04:25.220
그리고 기능이라 부르는 것들을 생각해내려고 노력하죠

04:25.220 --> 04:32.270
그리고 몇 가지 특징을 생각해 낼 거예요 아마존 베스트셀러 순위에 어떻게 올랐는지

04:32.270 --> 04:33.680
그런 거요

04:33.980 --> 04:41.060
그리고 이 세 가지 요소의 직선적 조합이 가격을 예측하는 데 도움이 되는지

04:41.060 --> 04:42.500
볼 거예요

04:42.500 --> 04:47.720
머신 러닝 모델을 다룰 때는 종종 거기서부터 시작하죠

04:48.050 --> 04:54.770
그리고 낱말 봉지라는 걸 할 거예요 자연 언어 처리를 처음 시도한

04:54.860 --> 04:56.180
것 중 하나죠

04:56.210 --> 05:02.240
NLP 단어 주머니는 특히 단순한 접근법입니다 말 그대로 단어 수를

05:02.240 --> 05:08.550
세고 작은 벡터를 만드는 거죠 이 설명에서 각각의 단어가 몇 번 기능하는지

05:08.550 --> 05:11.130
확인하는 거예요

05:11.130 --> 05:15.930
단어가 있다면 정지 단어는 포함하지 않습니다. 이런 단어는

05:15.930 --> 05:19.620
어떤 것과도 크게 다르지 않아요.

05:19.830 --> 05:26.880
하지만 인텔 같은 단어가 특정 값을 가진 노트북이나 컴퓨터를 뜻한다면

05:26.880 --> 05:30.600
인텔이 우리 단어 중 하나가 될 거예요

05:30.600 --> 05:35.580
그게 나타나느냐에 따라 혹은 나타난다면 그 장소에 얼마나 많이 나타나느냐에

05:35.580 --> 05:37.200
따라 달라져요

05:37.290 --> 05:44.670
각 제품에 들어간 단어 목록이 들어 있어요

05:44.850 --> 05:50.250
그런 다음 단어 봉지를 가져다가 이 다양한 단어들의 선형 조합이

05:50.250 --> 05:55.470
있는지 보겠습니다 그걸 다 합쳤을 때 제품 가격을 예측하죠

05:56.220 --> 06:01.980
그리고 워드 2 벡이라는 걸 사용할 겁니다 아까도 언급했지만

06:01.980 --> 06:10.310
최초의 실제 신경망 중 하나로 알고리즘을 인코딩하는 거죠 단어보다 더 영리한 방식으로

06:10.310 --> 06:13.100
벡터를 생성할 수 있어요

06:13.100 --> 06:15.950
그걸 먼저 선형 회귀와 함께 사용할 거예요

06:16.070 --> 06:22.790
그다음 무작위 포레스트에 사용할 겁니다 좀 더 복잡한 기술이죠 그때 말씀드릴게요

06:22.820 --> 06:30.560
하지만 벡터 비트 형태로 데이터와 기능을 무작위로 취하고 벡터 비트가 벡터인지

06:30.560 --> 06:37.880
아닌지를 확인한 후 이런 샘플 여러 개를 합친 일련의 모델로 앙상블을 생성하는

06:37.880 --> 06:40.190
걸 포함하죠

06:40.190 --> 06:47.480
그리고 벡터 회귀 지원이라는 것이 있습니다 벡터 머신의 지원 유형으로 다른

06:47.480 --> 06:53.660
기술입니다 데이터를 여러 그룹으로 분리하는 방법이죠

06:53.810 --> 06:55.880
다양한 기술을 시도해 볼 거예요

06:55.880 --> 07:03.050
어느 제품이 가장 잘 팔리고 제품 설명만 보고 가격을 예측하는 문제를

07:03.050 --> 07:06.710
해결할 수 있을지 지켜보죠

07:07.010 --> 07:09.410
그럼 주피터랩으로 가보죠
