WEBVTT

00:00.740 --> 00:03.290
結果を並べてみよう｡ 

00:03.290 --> 00:11.330
私たちは1ドルのコンスタントモデルから旅を始めた｡  全データの平均からの誤差46｡

00:11.330 --> 00:17.390
トレーニングデータセットでは､ 数個の特徴を持つ従来の機械学習モデルを見た｡ 

00:17.390 --> 00:18.590
1.0になった｡  39.

00:18.590 --> 00:20.810
平均的なランダムフォレストを上回った｡ 

00:20.810 --> 00:24.110
私たちの伝統的な機械学習モデルの最高峰が97に到達した｡ 

00:24.140 --> 00:35.270
人間は127ドル､ GPT4は76ドル､ そして我々の微調整されたカスタマイズモデルは47ドルに達した｡ 

00:35.390 --> 00:39.860
そして､ これはもちろん､ あなたへの挑戦につながる｡ 

00:39.890 --> 00:44.330
あなたの課題は､ この47ドルを改善することだ｡ 

00:44.450 --> 00:50.120
これはハイパーパラメーターの最適化で解決できることだ｡ 

00:50.180 --> 00:57.950
そうして今手元にあるタスクは､ ハイパーパラメータを実験的に弄って､ 重みとバイアスを使うことだ｡ 

00:57.980 --> 01:06.440
異なるオプティマイザー､ 異なる学習レート､ 異なるバッチサイズを検討し､ この数値を改善するために何ができるかを見てみよう｡

01:06.440 --> 01:11.130
また､ 推論時にモデルを実行する方法を変えて､ それが改善されるかどうかを調べることもできる｡ 

01:11.130 --> 01:18.810
そして､ おそらく最も小さな変化で結果に大きな影響を与えることができる方法のひとつが､

01:18.810 --> 01:31.560
データセットとデータ・キュレーションのステップをもう一度見直し､ より良い結果を得るために情報を促したり整理したりする別の方法を考えられないか､

01:31.560 --> 01:36.690
自分自身に挑戦することである｡

01:36.690 --> 01:42.390
そして最後にもうひとつ､ より大きなステップになるが､ とてもエキサイティングなことがある｡ 

01:42.390 --> 01:47.400
もしあなたがやらないなら､ 私は絶対にやるつもりだ｡ 

01:47.400 --> 01:54.480
ジャマを試し､ パワーハウスのクォンを試し､ フィの3人を試し､ 彼らのパフォーマンスを見る｡ 

01:54.720 --> 02:04.380
トークンを正しい数として予測できないかもしれないからだ｡

02:04.380 --> 02:06.420
それ以外は問題ないかもしれない｡ 

02:06.540 --> 02:10.470
でも､ それを試してみて､ それがとても美味しいということだと自分自身を納得させる必要がある｡ 

02:10.740 --> 02:12.990
だから､ いろいろなモデルを試してみてほしい｡ 

02:12.990 --> 02:22.100
また､ 4ビットではなく8ビットに量子化されたllama threeのバージョンで全体をやってみることもできる｡

02:22.100 --> 02:23.690
もっと大きなモデルもある｡ 

02:23.690 --> 02:31.250
確か140億のパラメータを持つ53のバージョンがあったと思うが､ それを試してみて､ 改善されるかどうかを確認することができるだろう｡

02:31.250 --> 02:33.590
それが目的だ｡ 

02:33.590 --> 02:37.850
これを40以下にできる最初の人の意見を聞きたい｡ 

02:37.880 --> 02:39.290
それは可能なはずだ｡ 

02:39.290 --> 02:50.030
価格決定の不確実性という現実を考えれば､ どこまで安くできるかは難しい限界のようなものがあると思う｡

02:50.030 --> 02:58.520
テストセットの251番目のアイテムで40ドル以内に収まるモデルを作るんだ｡

02:58.520 --> 03:06.620
だから､ 40を切ったら､ ぜひ私に連絡して､ あなたのハイパーパラメーターとモデルを教えてください｡

03:06.650 --> 03:08.270
私はそれが大好きだ｡ 

03:08.750 --> 03:11.750
それでは､ 今週を締めくくろう｡ 

03:12.470 --> 03:19.760
もちろん､ フロンティアAPIを使ってテキストやコードを生成したり､ オープンソースのモデルやハグフェイスを使って､

03:19.760 --> 03:29.190
データセットのキュレーションやベースラインモデル､ 微調整などの問題を解決することもできる｡

03:29.190 --> 03:39.570
そしてこの時点で､ フロンティアを凌駕するオープンソースモデルの選択とトレーニングの全プロセスを自信を持って実行することができる｡

03:39.570 --> 03:41.940
そしてそれは大きな成果だ｡ 

03:42.540 --> 03:48.360
来週がこのコースのフィナーレだが､ 約束しよう｡ 

03:48.360 --> 03:50.250
勝利になるだろう｡ 

03:50.430 --> 03:52.620
来週はとても楽しくなりそうだ｡ 

03:52.620 --> 03:54.660
ここまで来たのだから｡ 

03:54.690 --> 03:59.100
最後まで頑張って､ すべてがひとつになるのを見届けよう｡ 

03:59.130 --> 04:03.150
僕らがやってきたことをパッケージングして､

04:03.150 --> 04:09.120
APIの後ろにデプロイできるようにして､

04:09.120 --> 04:16.140
本番で使えるようにする｡

04:16.440 --> 04:23.010
そしてその時点で､ 商業的な問題に対する自分自身のエンド・ツー・エンドの解決策を生み出すことができるようになる｡

04:23.010 --> 04:27.240
画期的なllmsを使い､ 自分でトレーニングできるようになる｡ 

04:27.300 --> 04:31.740
来週が待ちきれないよ｡ 

04:31.830 --> 04:34.110
そしていつものように､ そこで会おう｡ 
