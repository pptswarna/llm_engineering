WEBVTT

00:00.740 --> 00:03.290
이제 결과를 나란히 보죠

00:03.290 --> 00:11.330
1달러짜리 모델로 여정을 시작했어요 데이터 평균에서 46개 오류예요

00:11.330 --> 00:17.390
훈련 데이터 세트에서 전통적인 머신 러닝 모델을 봤습니다 몇 가지 기능만 있었죠

00:17.390 --> 00:18.590
1까지 갔어요 39살요

00:18.590 --> 00:20.810
일반적인 숲을 능가하죠

00:20.810 --> 00:24.110
전통적인 머신 러닝 모델 중 최고는 97점이었어요

00:24.140 --> 00:35.270
참가자는 127점을 받았고 GPT는 4점을 받았습니다 미세하게 개조한 모델은 47점을 받았죠

00:35.390 --> 00:39.860
그래서 여러분에게 도전 과제를 드리려고 해요

00:39.890 --> 00:44.330
47달러를 더 벌어야 해요

00:44.450 --> 00:50.120
하이퍼파라미터 최적화가 큰 도움이 될 거예요

00:50.180 --> 00:57.950
이제 하이퍼파라미터 실험을 진행할 차례입니다 무게와 바이어스를 사용하는 작업이죠

00:57.980 --> 01:03.920
다양한 최적화 방법과 학습률 다양한 배치 크기를 고려해서 이 수치를

01:03.920 --> 01:06.440
개선할 방법을 찾아보세요

01:06.440 --> 01:11.130
모델을 추론 시간에 실행하는 다양한 방법을 탐구할 수도 있습니다 개선되었는지 보기 위해서요

01:11.130 --> 01:18.810
그리고 한 가지 요인이 더 있습니다 결과에 가장 큰 영향을 주는 방법으로 가장 작은 변화도

01:18.810 --> 01:25.500
만들 수 있는 거죠 데이터 세트와 데이터 큐레이션 단계를 다시 한 번 살펴보고

01:25.500 --> 01:31.560
정보를 프레젠테이션하거나 조직화하는 다양한 방법을 생각할 수 있는지

01:31.560 --> 01:36.690
도전하는 거예요 더 나은 결과를 위해서요

01:36.690 --> 01:42.390
마지막으로 할 수 있는 게 하나 더 있어요 더 큰 단계지만 아주 흥미진진하죠

01:42.390 --> 01:47.400
안 하면 제가 할 거예요 다른 모델도 써 보려고요

01:47.400 --> 01:54.480
JAM이나 권 장군을 써봐요 어떻게 하는지 보자고요

01:54.720 --> 02:00.360
좀 성가신 부분도 있어요 토큰 하나가 올바른 숫자라는 예측을 못 할 수도

02:00.360 --> 02:04.380
있거든요 비트는 추론 함수에서만 가능하니까요

02:04.380 --> 02:06.420
그것만 빼면 다 괜찮을 거예요

02:06.540 --> 02:10.470
하지만 실험해 보고 맛있다고 자신을 설득해야 해요

02:10.740 --> 02:12.990
다른 모델도 시도해 보세요

02:12.990 --> 02:19.040
라마3를 전체 버전으로 만들어도 돼요 4비트가 아니라 8비트로 수량화한

02:19.040 --> 02:22.100
거죠 여러분의 입맛에 따라서요

02:22.100 --> 02:23.690
큰 모델도 있어요

02:23.690 --> 02:29.540
53번 버전도 있어요 140억 개의 매개 변수를 실험해보고 개선되는지

02:29.540 --> 02:31.250
볼 수 있죠

02:31.250 --> 02:33.590
그게 목표예요

02:33.590 --> 02:37.850
Get 4만 이하로 맞추는 첫 번째 분께 듣고 싶네요

02:37.880 --> 02:39.290
그게 가능해야 해요

02:39.290 --> 02:45.440
불확실한 가격을 생각하면 얼마나 낮출 수 있는지에 엄격한 제한이 있는 것 같아요 하지만

02:45.440 --> 02:50.030
누군가는 40달러 이하로 낮출 수 있을 거예요 Get it

02:50.030 --> 02:57.650
테스트 세트에서 251번째 아이템에 대해 40달러 이내로 접근할 수 있는 모델을 구축합니다. 빨리 들어보고

02:57.650 --> 02:58.520
싶네요.

02:58.520 --> 03:04.130
그러니 40 이하로 떨어지면 연락 주세요 hyperpaameter와 모델을

03:04.130 --> 03:06.620
알려 주시면 제가 직접 만들어 볼게요

03:06.650 --> 03:08.270
그럼 좋죠

03:08.750 --> 03:11.750
이것으로 이번 주를 마무리하죠

03:12.470 --> 03:19.760
7주 차가 끝났으니 이제 프론티어 API로 텍스트와 코드 생성 오픈

03:19.760 --> 03:26.520
소스 모델 얼굴 포옹 데이터셋 큐레이션 기본 모델 미세 조정 같은

03:26.550 --> 03:29.190
문제를 해결할 수 있죠

03:29.190 --> 03:35.550
이 시점에서는 전 과정을 자신 있게 수행할 수 있습니다 한계를 뛰어넘을

03:35.550 --> 03:39.570
오픈 소스 모델을 선택하고 훈련하는 거죠

03:39.570 --> 03:41.940
대단한 성과죠

03:42.540 --> 03:48.360
다음 주에 이 과정의 결승전이 있어요 장담하는데 최고의 요리를 준비했죠

03:48.360 --> 03:50.250
대성공일 거예요

03:50.430 --> 03:52.620
다음 주는 정말 재미있을 거예요

03:52.620 --> 03:54.660
여기까지 왔잖아요

03:54.690 --> 03:59.100
끝까지 버텨서 모든 게 잘 어우러지는 걸 봐야죠

03:59.130 --> 04:03.150
우리가 할 아주 중요한 게 몇 가지 있어요 지금까지 한 걸 패키징하고

04:03.150 --> 04:09.120
API 뒤에서 배포할 수 있도록 하는 거죠 프로덕션 목적으로 사용할 수 있도록요 그런

04:09.120 --> 04:16.140
다음 모든 걸 응용 프로그램에 패키지하는 거죠 실제 영향을 줄 수 있는 응용 프로그램에요

04:16.440 --> 04:22.320
그 시점에 여러분은 상업적 문제에 대한 자신만의 해결책을 만들 수 있는 위치에 서게

04:22.320 --> 04:23.010
되죠

04:23.010 --> 04:27.240
획기적인 llm을 사용해 스스로 훈련할 수 있죠

04:27.300 --> 04:31.740
할 일이 많아요 다음 주가 기대돼요

04:31.830 --> 04:34.110
늘 그렇듯 거기서 봐요
