WEBVTT

00:01.340 --> 00:02.180
여러분

00:02.210 --> 00:04.250
무슨 생각하는지 알아요

00:04.250 --> 00:07.130
이번 주는 훈련 주간이었어야 해요

00:07.160 --> 00:11.900
개척 시대 모델들을 세심하게 조정하는 일을 시작했죠

00:11.900 --> 00:13.250
우리가 안 한 게 뭐죠?

00:13.250 --> 00:15.110
개척 시대 모델은 잘 몰라요

00:15.110 --> 00:16.490
좋은 소식이 있어요

00:16.490 --> 00:18.140
오늘이 그날이에요

00:18.170 --> 00:19.460
오늘이 그날이에요

00:19.460 --> 00:25.550
하지만 오늘 우리가 실망할 수도 있다는 걸 미리 알려드리죠

00:25.580 --> 00:26.720
곧 알게 되겠죠

00:26.900 --> 00:35.720
하지만 그걸 각오해야 해요 완전히 새로운 세상에 나가 드디어 훈련을 시작하니까요

00:35.720 --> 00:42.710
간단히 요약하자면 프런티어 모델과 API로 텍스트와 코드를 생성할 수 있고

00:42.710 --> 00:51.140
파이프라인과 하위 레벨 트랜스포머 API를 서로 끌어안는 오픈 소스 모델을 사용할 수 있죠

00:51.140 --> 00:59.390
모델을 직접 사용하는 것처럼 랭 체인이 아닌 래그 파이프라인을 만들 수 있어요

00:59.390 --> 01:06.620
가장 중요한 건 큐레이팅에 많은 시간을 들이는 문제 해결을 위한 5단계 전략을

01:06.650 --> 01:09.110
따를 수 있다는 거죠

01:09.140 --> 01:13.910
많은 시간을 데이터를 큐레이팅하고 기준 모델을 만드는 데 할애하죠

01:13.910 --> 01:16.760
훈련을 좀 했지만 기본 모델 훈련이었어요

01:16.790 --> 01:22.970
전통적인 ML은 아직 완성되지 않았어요 미세하게 훈련된 개척지 모델이죠

01:22.970 --> 01:24.500
오늘 그걸 할 거예요

01:24.530 --> 01:30.170
모델 앞에서 미세 튜닝 과정을 이해하고 데이터 세트를 생성하고 미세

01:30.200 --> 01:35.360
튜닝을 실행한 후 새 미세 튜닝 모델을 테스트하는 거죠

01:35.930 --> 01:42.290
훈련에 대해 설명하자면 이런 모델에서 세밀한 조정은

01:42.290 --> 01:48.290
훈련과 동의어입니다 물론 처음부터 훈련하진 않습니다

01:48.290 --> 01:54.020
그러면 수억 달러가 들 테니까요

01:54.020 --> 02:00.680
우리는 항상 훈련된 기존 모델을 사용합니다 미리 훈련된 모델이죠 전송 학습을

02:00.680 --> 02:05.670
활용해 더 많은 훈련을 합니다 이 이론은 기존에 훈련된

02:05.670 --> 02:10.410
모델을 가지고 더 많은 훈련을 하면 새 작업에서 더 낫다는

02:10.410 --> 02:12.030
거죠

02:12.120 --> 02:14.760
그걸 미세 조정이라고 하죠

02:15.450 --> 02:24.030
이제 어휘력 문제를 해결했으니 오픈AI를 조정하는 세 가지 단계에 대해 이야기해 보죠

02:24.180 --> 02:30.930
GPT 40과 4 미니를 받아들이려면 세 가지를 따라야 합니다 이 세

02:30.930 --> 02:33.390
가지를 잘 조율해야 하죠

02:33.420 --> 02:39.270
첫 단계는 훈련에 사용할 훈련 데이터를 준비하는 거예요

02:39.270 --> 02:44.820
전통적인 모델의 맥락에서 훈련 데이터를 사용합니다 선형 회귀 같은 거죠

02:44.820 --> 02:49.170
훈련용 견본을 구해서 선형 회귀 모델로 주입했어요

02:49.170 --> 02:50.790
훈련 데이터를 만들어야 해요

02:50.820 --> 02:54.720
이제 오픈AI에 업로드 해야 해요

02:54.720 --> 03:02.520
JSON L이라는 특정한 포맷의 훈련 데이터를 기대합니다 JSON 라인을 약자로 하죠

03:02.670 --> 03:07.160
미묘하게 달라요 일반적인 JSON을 보여드리죠

03:07.640 --> 03:13.880
그다음 훈련과 미세한 조율을 실시할 겁니다 이 도표들은 모두 아래를 가리키죠

03:13.880 --> 03:14.900
당신이 곤란해질지도 몰라요

03:14.930 --> 03:20.270
뭔가 잘못되고 있는 것처럼 보이지만 그 반대입니다 훈련할 때 여러분의 상대는 지켜보고 있죠

03:20.300 --> 03:21.590
훈련의 손실이죠

03:21.710 --> 03:23.960
물론 손실이 줄어들길 바라죠

03:23.960 --> 03:25.880
상황이 나아지고 있다는 뜻이죠

03:25.970 --> 03:31.610
그래서 매의 눈으로 도표를 보면서 손실이 줄어드는지 확인할

03:31.610 --> 03:32.480
거예요

03:33.200 --> 03:39.560
가장 중요한 것은 한 배치에서 트레이닝 손실과 유효성 검증 손실입니다.

03:39.590 --> 03:44.090
데이터 집합에 있는 것이죠.

03:44.090 --> 03:45.740
저것도 내려가요?

03:45.770 --> 03:49.940
훈련 데이터에 과부하가 걸릴 수 있으니까요

03:49.970 --> 03:55.940
사실 우리 경우엔 그게 문제가 아닙니다 트레이닝 데이터로 한 개의 epoch만 실행할

03:55.940 --> 03:56.990
테니까요

03:56.990 --> 03:58.850
이포크라고도 하죠

03:58.940 --> 04:04.340
훈련 데이터를 통해 완전한 훈련을 한 다음 같은 데이터를

04:04.340 --> 04:07.370
반복해서 실행하는 거죠

04:07.400 --> 04:10.070
그런 걸 두 번째 수련 시대라고 하죠

04:10.490 --> 04:16.130
하지만 그렇게 하지 않을 겁니다 훈련 데이터가 너무 많아서 그럴 필요가 없으니까요

04:16.130 --> 04:19.580
트레이닝 데이터를 더 활용해 하나의 시대를 만드는 게 낫겠어요 비트 코스트

04:19.580 --> 04:26.360
모든 데이터는 항상 새로운 데이터이기 때문에 훈련의 손실은 검증의 손실만큼이나

04:26.360 --> 04:27.230
유용하죠

04:28.100 --> 04:31.760
그리고 마지막으로 결과를 평가하죠

04:31.760 --> 04:38.240
그걸 바탕으로 수정하고 반복해서 계속하는 거죠

04:38.390 --> 04:40.310
그게 무대예요

04:41.060 --> 04:44.870
말씀드렸듯이 첫 번째는 데이터를 준비하는 거죠

04:45.050 --> 04:52.970
OpenAI는 JSON L이라는 포맷에서 그걸 기대합니다 JSON 데이터의 일련의 라인이라는

04:52.970 --> 04:53.750
뜻이죠

04:53.900 --> 04:56.030
JSON 데이터와 똑같다고 생각하실지도 몰라요

04:56.030 --> 04:56.870
아니에요

04:56.870 --> 04:59.000
컬렉션에 있는 게 아니에요

04:59.000 --> 04:59.900
목록에 없군요

04:59.900 --> 05:02.770
쉼표가 붙은 대괄호로 시작하진 않아요

05:02.770 --> 05:11.410
이 파일의 각 행, 각 줄은 중괄호로 시작하고 끝나는 별개의 JSON 객체예요

05:11.410 --> 05:16.270
미묘한 차이점이지만 JSON 개체를 작성하지 않을 거라는 기대는 안 할 경우에

05:16.270 --> 05:19.390
걸릴 수 있어요 주변에 리스트가 있을 테니까요

05:19.390 --> 05:26.320
이 파일에 JSON 행을 작성하는 거죠 그럼 각각의 행은 우리에게 아주 익숙한

05:26.320 --> 05:27.550
것이 돼요

05:27.580 --> 05:30.730
메시지라는 하나의 특성을 갖게 되죠

05:30.730 --> 05:38.890
그 안에는 우리가 잘 아는 것이 들어있습니다 각 사전마다 역할과 내용이 있는

05:38.920 --> 05:40.750
사전 목록이죠

05:40.750 --> 05:42.100
대화예요

05:42.100 --> 05:45.460
각 행에 들어가는 거죠

05:45.610 --> 05:51.040
보다시피 업로드를 위한 이 특정 유형의 데이터 세트를 만들 거예요

05:52.240 --> 05:53.260
좋아요

05:53.680 --> 05:57.130
잡담은 이 정도면 충분해요

05:57.160 --> 05:58.900
주피터 연구소로 가요

05:58.900 --> 06:01.000
실제로 실행해보죠

06:01.000 --> 06:05.230
그리고 처음으로 개척지 모델을 훈련할 거예요

06:05.260 --> 06:06.370
시작하죠
