WEBVTT

00:00.050 --> 00:08.120
そして次は､ 私のお気に入りのモデルであり､ 一般的に多くのデータサイエンティストが好むモデルであるアントロピックのクロードに話を移そう｡

00:08.120 --> 00:15.020
最新版のクロード3｡  5 10月に発表されたソネット・ニューは､ 現在ほとんどのベンチマークで首位に立っており､

00:15.050 --> 00:20.870
この地球上でおそらく最強のLLMであることを示している｡

00:20.900 --> 00:24.080
クロードにとって難しい質問から始めよう｡ 

00:24.080 --> 00:29.240
嫉妬するってどんな感じ？

00:30.590 --> 00:32.450
この答えを見てどう思う？

00:32.480 --> 00:40.340
そうすれば､ 思慮深く､ 興味深く､ 驚くほど洞察に富んだものが返ってくるはずだ｡

00:40.370 --> 00:44.420
私の理解では､ それは経験しないという事実をほのめかしている｡ 

00:44.420 --> 00:50.480
嫉妬そのものは､ しばしば恐怖や不安､ 胃の締め付けられるような欲望として現れる｡ 

00:50.480 --> 00:56.540
だから､ ほとんど生物学的な感覚で､ 胸が焼けるような感覚になる｡ 

00:56.780 --> 01:00.590
焦るような思い､ つまり物足りなさや脅威を感じる｡ 

01:00.620 --> 01:02.570
実に興味深い｡ 

01:02.570 --> 01:04.040
説得力のある答えだ｡ 

01:04.070 --> 01:07.140
そのような難しい質問はまったく問題ない｡ 

01:07.170 --> 01:07.680
オーケー｡ 

01:07.710 --> 01:15.000
この文章にAという文字が何回出てくるか聞いてみよう｡ 

01:16.500 --> 01:18.300
どう処理するか見てみよう｡ 

01:18.330 --> 01:20.700
数えてみよう｡ 

01:20.700 --> 01:21.660
間違っている｡ 

01:22.590 --> 01:24.420
人類の希望はまだある｡ 

01:24.510 --> 01:31.860
ええと､ それで､ クロードは5回数えて､ それについてまた間違った説明をする｡ 

01:31.890 --> 01:34.710
この種の質問がなぜ難しいかは､ 後でわかるだろう｡ 

01:34.710 --> 01:36.240
だから､ 今のところゼロだ｡ 

01:36.240 --> 01:39.870
それに対応できたのは､ ワンプレビューだけである｡ 

01:40.050 --> 01:40.590
分かった｡ 

01:40.590 --> 01:49.980
他のフロンティアのLLMと比べて､ どのような質問に答えるのが最も得意で､ どのようなことに最もやりがいを感じますか？

01:50.250 --> 01:53.340
あなたと比較する他人は？

01:53.370 --> 01:56.130
クロードから得たものは興味深い｡ 

01:56.130 --> 02:04.830
これは､ モデルにおける安全性と整合性の必要性についての人類学的な強い見解と結びついている｡

02:05.010 --> 02:09.690
私は自分の倫理観を尊重しながら､ 率直で透明性のある人間でありたいと思っています｡ 

02:09.690 --> 02:14.480
他のAIモデルとの比較を主張するのは気が引ける｡ 

02:14.480 --> 02:18.110
そして､ 自らの長所と短所を教えてくれる｡ 

02:18.110 --> 02:20.630
とても興味深い答えだ｡ 

02:21.200 --> 02:28.310
それに比べて､ GPTに戻って同じ質問をしてみれば､

02:28.310 --> 02:34.130
GPTがどう答えるかわかるだろう｡

02:34.130 --> 02:41.090
どこが一番強いのか､ 課題は何か､ そしてそれを補うものは何か､ はっきりしたものが得られるはずだ｡ 

02:41.600 --> 02:50.570
つまり､ ChatGPTにウェブ・ブラウジングとコード・インタプリタ､ つまりキャンバス・ピースのクロードという名前だと思う｡

02:50.600 --> 02:58.460
比較対象としてinterestlyと表示され､ その後にBarred by Googleと表示されている｡

02:58.820 --> 03:04.850
しかし､ 主な競争相手を示し､ いくつかの違いについて語っているのは興味深い｡ 

03:04.850 --> 03:05.510
そして､ これを見てほしい｡ 

03:05.510 --> 03:15.870
魅力的なことに､ クロードはより広範な社会倫理的考察について､ より思慮深い回答をしており､ それは私の技術的な焦点を補うことができる｡

03:15.870 --> 03:25.260
GPT4がそのような比較能力を持っているだけでなく､ 実によく検討された答えを出しているのは魅力的だ｡

03:25.290 --> 03:27.600
だから特に興味深いと思ったんだ｡ 

03:28.140 --> 03:28.650
分かった｡ 

03:28.650 --> 03:33.330
ともあれ､ これでクロードの機能の一部を簡単に紹介できた｡ 

03:33.330 --> 03:39.690
また､ クロードはコーディングが得意で､ あなたと一緒にコードを考えてくれる｡ 

03:39.750 --> 04:00.150
例えば､ オープンAI APIを使ったPythonのサンプルコードを教えてください｡

04:00.450 --> 04:04.620
これをどう処理するか見てみよう｡ 

04:04.620 --> 04:14.970
つまり､ 右側にあるアーティファクトと呼ばれる別のコードにコードを作成します｡

04:15.150 --> 04:20.220
その結果､ ここに多くのコードが生まれた｡ 

04:20.220 --> 04:26.150
私たちがオープンAIと呼んでいるものですが､ クライアントがあり､ コードチャットの完了がドットクリエイトされ､

04:26.360 --> 04:32.300
その結果がレスポンスのドットチョイスであり､ メッセージの内容がゼロドットであることがわかると思います｡

04:32.330 --> 04:35.630
前回もそうだったので､ 少しはお分かりいただけただろうか｡ 

04:35.630 --> 04:37.160
それをクラス分けしたんだ｡ 

04:37.160 --> 04:38.690
いくつかの例がある｡ 

04:38.690 --> 04:47.210
アーティファクトと呼ばれるもので､ キャンバスがGPT 4で機能する方法とは少し違います｡

04:47.210 --> 04:53.120
少し違うが､ このファイル､ アーティファクトを見ることができ､ それを公開して他の人と共有したり､

04:53.120 --> 04:56.060
ダウンロードしたりすることができる｡

04:56.060 --> 05:02.000
だから､ クロードをキャンバスに使うのと同じようなものだ｡ 

05:02.000 --> 05:04.220
そして､ そのためのとてもパワフルな方法を教えてくれる｡ 

05:04.220 --> 05:09.620
そして､ 相互作用によって､ このアーティファクトを変更するのではなく､ より多くの異なるアーティファクトを生み出すことになる｡ 

05:09.650 --> 05:14.030
また､ そのような経験があると､ 一緒に仕事をしたときに､ すべての異なるバージョンのファイルを遡って見ることができるので､

05:14.030 --> 05:17.150
便利なこともある｡

05:17.150 --> 05:19.760
これでクロードを少し案内したことになる｡ 

05:19.760 --> 05:26.390
アラインメントと安全性､ そしてアーティファクトの作り方だ｡ 
