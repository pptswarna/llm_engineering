WEBVTT

00:00.830 --> 00:01.940
ようこそ｡ 

00:01.940 --> 00:02.870
3週目だ｡ 

00:02.870 --> 00:03.800
4日目だ｡ 

00:03.830 --> 00:12.890
私たちはオープンソースの土地での冒険に戻り､ オープンソースのモデル上で推論を実行する方法を調査している｡

00:13.130 --> 00:17.120
そして今日は､ 『ハギング・フェイス』のモデルクラスを見てみよう｡ 

00:17.120 --> 00:20.390
当初はパイプラインAPI､ つまりハイレベルAPIについて話をした｡ 

00:20.420 --> 00:26.090
その後､ 低レベルのAPIについて話し始めた｡ トーケナイザーから始まり､ 今度はモデルについてだ｡ 

00:26.150 --> 00:28.580
では､ すでに何ができるのか？

00:28.610 --> 00:33.290
もちろん､ フロンティアモデルを使ったコーディングに加え､ マルチモーダルAIアシスタントの構築や､

00:33.290 --> 00:38.270
現在できることは､ 抱き顔､ パイプライン､ トークナイザーを使うことだ｡

00:38.300 --> 00:41.270
新しいスキル､ 新しいクラス｡ 

00:41.270 --> 00:51.860
実際にトランスフォーマーを作成し､ それを実行してテキストを生成するのだ｡

00:51.860 --> 00:56.300
そして､ 5つの異なるモデルの結果を比較する｡ 

00:56.300 --> 01:07.910
そのうちの3つを一緒にやって､ あとの2つで実験してもらうつもりだ｡

01:08.300 --> 01:10.700
だから､ とても楽しいはずだよ｡ 

01:10.970 --> 01:13.380
だから､ モデルたちはそれを導入した｡ 

01:13.380 --> 01:21.330
今回もリャマ3世と仕事をすることになる｡  1､ metaのフラッグシップで画期的なモデル｡ 

01:21.330 --> 01:29.670
今回は､ マイクロソフトのオープンソースモデルであるファイ3と､ グーグルのジェンマを取り上げる｡ 

01:29.670 --> 01:32.190
小さいよ｡ 

01:32.190 --> 01:36.450
ジェミニのいとこにあたるのがグーグルのジェンマだ｡ 

01:36.510 --> 01:41.880
他にも2つのモデルがあるので､ 自分で試してみてほしい｡ 

01:41.910 --> 01:49.830
一人はミストラルのミストラルで､ もう一人はクイン2の強豪だ｡ 

01:50.040 --> 01:53.190
そしてQuantuを楽しんで使ってほしい｡ 

01:54.270 --> 02:02.160
そこで今回は､ ハギング・フェイス・フレームワークでオープンソースのモデルを扱う際の3つの側面についても取り上げます｡

02:02.430 --> 02:05.610
その最初のものは量子化と呼ばれるものだ｡ 

02:05.640 --> 02:13.080
そしてこれは､ モデルの重みの精度を下げることで､ メモリに収めやすくし､ ロードしやすくし､

02:13.080 --> 02:16.860
さらに高速に実行できるようにすることである｡

02:16.860 --> 02:25.290
量子化というのは､ 例えばローエンドのGPUボックスで作業することを可能にする非常に重要なテクニックだ｡

02:25.330 --> 02:34.480
そしてトレーニングに入ると､ 量子化を使えるかどうか､ 大規模なオープンソースモデルをトレーニングできるかどうかが絶対的に重要になる｡

02:34.510 --> 02:42.040
実際､ 私が言っているのを聞いたことがあると思うが､ 今､ Qローラ､ これは数週間後に使うテクニックの名前だ｡

02:42.040 --> 02:45.460
そしてQとQ､ ローラは量子化を意味する｡ 

02:45.460 --> 02:49.960
だから､ この旅では量子化に何度か直面することになる｡ 

02:50.650 --> 02:54.580
今日はモデルの内部も見てみよう｡ 

02:54.580 --> 03:00.310
だから､ このクラスは理論的というより実践的なクラスなんだ｡ 

03:00.460 --> 03:02.050
しかし､ これはその瞬間のひとつになるだろう｡ 

03:02.050 --> 03:10.750
そして､ ハグする顔のトランスフォーマーライブラリの後ろにあるPyTorchレイヤーがどのようなものか､

03:10.780 --> 03:12.970
中を覗いてみよう｡

03:13.720 --> 03:21.520
そしてまた､ 我々はこの時点でストリーミングに慣れ親しんでいるので､ 結果をストリーミングできるようにしたいということはほとんど言うまでもない｡

03:21.520 --> 03:26.290
そこで､ オープンソースのモデルを使って､ どのように結果を出すことができるかを紹介しよう｡ 

03:26.290 --> 03:32.440
このように､ ハグフェイスのための低レベルのAPI上で推論を実行するための航海の中で､ 私たちが調べようとしているのは､

03:32.440 --> 03:35.710
ちょっとした余分な部分なのだ｡

03:35.740 --> 03:36.940
話はもう十分だ｡ 

03:36.940 --> 03:38.350
さっそく始めよう｡ 
