WEBVTT

00:00.350 --> 00:08.060
というわけで､ Google ColabでGPUボックスを使ったクラウド上での最初の共同セッションを行うことになった｡ 

00:08.090 --> 00:15.110
その点､ 私はT4ボックスという低スペックのボックスに接続したことがある｡ 

00:15.350 --> 00:16.880
私のリソースはここで見ることができる｡ 

00:16.880 --> 00:24.170
GPUのほとんどを満タンにすることができたが､ ランタイムでセッションをリスタートしたところ､

00:24.200 --> 00:31.520
GPUメモリがゼロになった｡

00:31.520 --> 00:36.230
とにかく､ このスクリーンを外して､ 邪魔にならないようにしよう｡ 

00:36.680 --> 00:37.550
これでよし｡ 

00:37.940 --> 00:41.210
それと､ 僕らのコラボを見てよ｡ 

00:41.210 --> 00:51.710
というわけで､ パイプラインの世界を紹介することから始めよう｡ ハグしている顔のトランスフォーマー・ライブラリーには､ パイプラインという2つのAPIレベルがあることを思い出してほしい｡

00:51.710 --> 00:55.670
そして後ほど､ トーケナイザーと今日のモデルを紹介する｡ 

00:55.670 --> 01:11.440
パイプラインがすべてであり､ 数行のコードで一般的なタスクの推論を実行できる高レベルのAPIである｡

01:11.950 --> 01:16.360
使い方は超シンプルだ｡ 

01:16.690 --> 01:23.920
まずパイプラインを呼び出し､ 実行したいタスクを文字列で渡す｡ 

01:23.920 --> 01:29.830
だから､ ここにいろいろなものを､ いろいろな文字列を渡すことができる｡

01:29.830 --> 01:35.200
パイプライン・オブジェクトが返ってくるので､ それを入力で呼び出すと､ 結果が返ってくる｡ 

01:35.200 --> 01:36.760
それだけだ｡ 

01:36.760 --> 01:37.930
単純なことだ｡ 

01:38.020 --> 01:44.170
だから､ まずはトランスフォーマーのライブラリーをインストールするところから始めようと思う｡

01:44.170 --> 01:48.640
Datasetsは､ ハグする顔､ データセットにアクセスできるライブラリだ｡ 

01:48.640 --> 01:55.210
ディフューザーは､ 画像を生成する拡散モデルについて語るとき､ トランスフォーマーのコンパニオン・ライブラリーのようなものだ｡

01:55.240 --> 02:05.250
私がトランスフォーマーと言う場合､ 画像を生成するときのために､ トランスフォーマーとその兄弟ライブラリであるディフューザーの両方を指すことが多い｡

02:05.250 --> 02:07.920
だからpipでインストールしている｡ 

02:08.040 --> 02:15.330
セルのaの前に感嘆符がある場合は､ それをターミナル・コマンドとして実行することを意味する｡

02:15.330 --> 02:16.530
そして､ それは実行される｡ 

02:16.530 --> 02:29.790
マイナスQはクワイエットモードにすることで､ すべてのパッケージをインストールする際の出力が出ないようにする｡

02:29.790 --> 02:33.210
これらのパッケージがインストールされるまで､ 30秒かかるかもしれない｡ 

02:33.510 --> 02:36.030
そして､ 輸入をするんだ｡ 

02:37.590 --> 02:43.020
それが終わったら､ パイプラインに取り掛かろう｡ 

02:43.050 --> 02:44.490
覚悟しておけ｡ 

02:44.490 --> 02:50.220
つまり､ まずセンチメント分析とは､ 肯定的または否定的なテキストを分析することである｡ 

02:50.220 --> 02:56.670
そして､ LMマスターへの道を歩んでいることにとても興奮している､ というところから始めるつもりだ｡ 

02:56.790 --> 02:59.940
それがプラスなのかマイナスなのか｡ 

03:00.120 --> 03:03.500
というわけで､ さっそくいくつか注意しておきたいことがある｡ 

03:03.710 --> 03:10.250
まず第一に､ モデルが提供されていないことを警告し､ この特定のモデルがデフォルトになっている｡ 

03:10.250 --> 03:19.790
つまり､ model equalsと言って､ このパイプラインの一部として使用したい抱きつき顔ハブのモデルを指示することができるということだ｡

03:19.790 --> 03:25.880
何も指定しなければ､ そのタスクのデフォルトを選ぶだけだ｡

03:26.090 --> 03:32.600
もうひとつは､ GPUが使用可能な環境であることを教えてくれているのだが､

03:32.600 --> 03:37.430
GPUを使用するように指示していない｡

03:37.460 --> 03:46.100
このコマンドは､ このパイプラインを使いたい､ 我々が持っているGPUを活用したい､

03:46.100 --> 03:51.290
ということを伝える｡

03:52.130 --> 03:57.050
GPUで実行した｡ 

03:57.050 --> 03:59.330
そして､ 結果にも目を向けるべきかもしれない｡ 

03:59.330 --> 04:06.460
その結果､ この発言は肯定的な発言とみなされ､ その信頼度を示すスコアは実に高いものとなった｡

04:06.460 --> 04:08.080
それはいいことだ｡ 

04:08.080 --> 04:11.560
おそらく､ この文章の解釈は正しいと思う｡ 

04:11.560 --> 04:13.960
notという単語を入れてみよう｡ 

04:13.990 --> 04:18.010
LLMマスターへの道を歩んでいることに､ それほど興奮はしていない｡ 

04:18.040 --> 04:18.970
考えもしなかった｡ 

04:18.970 --> 04:22.120
一瞬でもそう思っていないことを願うが､ 一応確認しておこう｡ 

04:22.120 --> 04:31.090
もしそう言うなら､ そのレッテルは否定的なものであり､ それが本当に否定的な発言であることは間違いない｡

04:31.090 --> 04:35.440
というわけで､ うまくいった｡ 

04:35.470 --> 04:37.630
そうでないと思わせたいのだ｡ 

04:38.080 --> 04:40.720
名前付きエンティティ認識は次のタスクである｡ 

04:40.720 --> 04:44.890
私はパイプラインをガチャガチャやるだけだから､ 全部自分でやってみてほしい｡ 

04:44.920 --> 04:53.080
もちろん､ 名前付きエンティティ認識とは､ テキストを提供し､ それがどのようなものを指しているかを識別するようモデルに求めることである｡

04:53.110 --> 04:56.500
これは私が撮った標準的なものだ｡ 

04:56.530 --> 05:00.310
バラク・オバマは第44代アメリカ合衆国大統領である｡ 

05:00.670 --> 05:15.840
そして､ それを分析するように頼むと､ ここに2つの異なる名前の実体があると答える｡

05:15.960 --> 05:22.590
この文章を見ていただければわかると思うが､ 最初の名前付きエンティティはperersonのようにper型である｡ 

05:22.950 --> 05:27.030
バラク・オバマだ｡ 

05:27.120 --> 05:33.510
そして2つ目は場所のロックで､ 単語はUnited States｡ 

05:33.510 --> 05:38.850
もちろん､ それが入力のどこにあるのかを教えてくれる｡ 

05:39.300 --> 05:46.860
データ・サイエンスでは非常に一般的なユースケースであり､ 自由に使えて､ 素早く実行できる素晴らしいものだ｡

05:47.160 --> 05:53.010
コンテキストを利用した質問回答では､ 質問回答パイプラインを作成することができます｡ 

05:53.010 --> 06:02.640
そしてまた､ このデバイスのCudaを使ってGPUで実行し､ 第44代アメリカ大統領は誰だったのか？

06:02.640 --> 06:11.480
だから､ 何か見上げるものがあって､ そこに結果をプリントするように頼む｡

06:11.480 --> 06:12.170
私はそう思う｡ 

06:12.170 --> 06:14.750
私は今､ このモデルのパワーを誇示したいわけではない｡ 

06:14.750 --> 06:17.930
パイプラインAPIのシンプルさをアピールしたいんだ｡ 

06:17.960 --> 06:23.420
より洗練された文脈や､ より良い質問で遊ぶことができます｡ また､ ハギング・フェイス・ハブで利用可能なさまざまなモデルのいくつかを探求するために､

06:23.660 --> 06:29.540
異なるモデルでパスを試してみることをお勧めします｡

06:30.110 --> 06:32.780
テキストの要約も簡単だ｡ 

06:32.810 --> 06:35.360
もちろん､ パイプラインもそうだ｡ 

06:35.360 --> 06:39.770
タイプは要約で､ 大量のテキストを入れることができる｡ 

06:39.800 --> 06:44.840
ここでは､ 私は一般的に抱擁顔トランスフォーマーライブラリについて噴出していることについて話している｡ 

06:45.290 --> 06:56.180
要約を依頼し､ 長さの最小値と最大値を指定すると､ その文章を要約した短くてシャープな文章が返ってくる｡

06:56.300 --> 07:00.530
それに､ ほとんど僕がすでに入れたものを切り刻んだだけなんだ｡ 

07:00.530 --> 07:03.590
だから素晴らしい仕事をしたとは言えないが､ かなりシンプルなモデルだ｡ 

07:03.590 --> 07:07.650
繰り返しになるが､ より優れたモデルから､ より優れた要約を探ることができる｡ 

07:07.920 --> 07:11.400
お時間があれば通訳しますよ｡ 

07:11.430 --> 07:13.740
英語への翻訳｡ 

07:13.740 --> 07:14.610
フランス人へ｡ 

07:15.060 --> 07:21.450
データサイエンティストたちは､ Hugging FaceパイプラインAPIのパワーとシンプルさに本当に驚いていた｡ 

07:21.930 --> 07:28.260
そして､ フランス語を話す皆さんのために､ その性能を見てみよう｡ 

07:28.290 --> 07:39.720
私の高校生のフランス語で十分だと言うつもりはないが､ 抱きつき顔のパイプラインのAPIのパワーとシンプルさに驚かされたと言えるだろう｡

07:39.720 --> 07:45.330
そして､ 私の乏しいフランス語能力を見る限り､ かなりしっかりした翻訳のようだ｡ 

07:45.330 --> 07:52.230
非常に簡単な分類､ あるいはゼロショット分類と呼ばれるもので､ 事前の例を与えることなく､

07:52.230 --> 07:57.600
ただ例を与えてラベルを付けるよう求めるものだ｡

07:57.810 --> 08:06.150
だから私たちは､ テキストを抱きしめている顔のトランスフォーマーのライブラリーは素晴らしいし､ テクノロジーやスポーツや政治を分類するよう求めている｡

08:06.150 --> 08:08.660
そして､ そのパフォーマンスを見てみよう｡ 

08:09.050 --> 08:15.200
ええと､ ラベルには､ ええと､ テクノロジー用って書いてある｡ 

08:15.230 --> 08:20.810
点数は95％で､ スポーツと政治の点数はごくわずかだ｡ 

08:20.810 --> 08:21.500
政治だ｡ 

08:21.500 --> 08:23.090
その中で最も低い｡ 

08:23.180 --> 08:29.360
特に技術に直接関係するような言葉はなかったからね｡ 

08:29.360 --> 08:31.100
全然悪くないよ｡ 

08:31.430 --> 08:37.340
そして､ このシリーズ最後の本当にシンプルなものは､ テキスト生成だ｡ 

08:37.370 --> 08:43.160
Huggingfaceのパイプラインを使う上で覚えておいてほしいことがあるとすれば､ それは......そうだな｡

08:43.190 --> 08:46.910
明らかにバニラモデルを使用しているが､ どのように処理されるか見てみよう｡ 

08:48.830 --> 08:54.350
それは､ ノーチラス上で実行されるアプリケーションは､ あたかもコンパイルされたかのように､ ターゲットとして抱きつき顔パッケージを生成するということだ｡

08:54.350 --> 08:55.340
だから､ ちょっとランダムなんだ｡ 

08:55.340 --> 08:59.720
私のいくつかの､ ええと､ ええと､ 以前のテストではもっとうまくいった｡ 

08:59.900 --> 09:02.030
それは､ 彼らがどれだけ優れているか､ 回復力があるかということだ｡ 

09:02.060 --> 09:04.400
どんなプロジェクトでもそうだが､ 自分のリスク許容度を覚えておく必要がある｡ 

09:04.430 --> 09:05.630
追い込むタイミングを忘れない｡ 

09:05.660 --> 09:09.520
だからもちろん､ それがどのように始まると考えているかに基づいて漫然としている｡ 

09:09.520 --> 09:13.210
もっと面白いスタートを試してみて､ そのパフォーマンスを見てみるといい｡ 

09:13.210 --> 09:17.260
もっと大きくて頑丈なモデルを試してみるのもいい｡ 

09:17.290 --> 09:20.980
もちろん､ テキスト生成という点では､ その方がより正確だ｡ 

09:21.700 --> 09:22.420
オーケー｡ 

09:22.420 --> 09:30.970
そしてもちろん､ 皆さんはマルチモダリティの専門家ですから､ 画像生成をお見せしましょう｡

09:30.970 --> 09:35.800
ここまではすべてトランスフォーマー・ライブラリーを使ってきましたが､ ここからはディフューザー（拡散スタイル・モデル）､

09:35.800 --> 09:41.590
つまり画像を生成するアーキテクチャに切り替えます｡

09:41.860 --> 09:50.080
そして､ 私たちはよく知られた安定拡散モデルを使用している｡

09:50.110 --> 09:51.010
ご覧の通りだ｡ 

09:51.040 --> 09:54.010
使用するデータ型を伝える必要がある｡ 

09:54.400 --> 10:00.640
そうしてGPUに表示させたら､ テキストを表示させることができる｡ 

10:00.640 --> 10:08.130
そして､ サルバドール・ダリのシュールなスタイルでAIについて学ぶデータサイエンティストのクラスで､ そのイメージを生成しよう､

10:08.400 --> 10:11.010
と言っているんだ｡

10:11.010 --> 10:13.050
これにはもう少し時間がかかる｡ 

10:13.050 --> 10:15.510
もう少し肉付きのいい仕事だ｡ 

10:15.750 --> 10:21.390
ええと､ あなたにとってはもっと時間がかかるかもしれない｡ 

10:21.390 --> 10:26.880
こうしてモデルはHuggingfaceからダウンロードされ､ ローカルディレクトリに保存された｡ 

10:26.880 --> 10:30.960
だから､ 実行すると1分以上かかるかもしれない｡ 

10:31.200 --> 10:32.970
うーん､ でもこれでいい｡ 

10:32.970 --> 10:44.490
ダリの超現実的なスタイルでAIについて学ぶデータ・サイエンティストのクラスがここにある｡

10:44.490 --> 10:45.960
大好きだよ｡ 

10:45.990 --> 10:47.760
この人たちに似ている？

10:47.970 --> 10:52.320
君の最悪の悪夢だけでないことを祈るよ｡ 

10:52.320 --> 10:55.110
これがシュールなダリだ｡ 

10:55.140 --> 10:57.840
怖くて､ 奇妙な世界だ｡ 

10:57.930 --> 11:01.350
データサイエンティストのクラスとしては､ とても気に入っている｡ 

11:01.380 --> 11:11.450
前回の講義でコードをフラッシュアップしたのを覚えているだろうか｡

11:11.630 --> 11:13.160
ああ､ ぜひそれを使ってくれ｡ 

11:13.160 --> 11:18.170
時間がかかることがわかるだろうし､ T4よりも頑丈なボックスで動作させる必要がある｡ 

11:18.200 --> 11:28.070
A100でやれば2､ 3分で終わるし､ 前回の講義でお見せしたような息をのむような良い画像が得られる｡

11:28.280 --> 11:34.520
ええと､ でも､ 手っ取り早く安いモデルとしては､ かなりいいんじゃないかと思うんだけど｡ 

11:35.120 --> 11:39.680
そして最後が､ オーディオの生成だ｡ 

11:39.680 --> 11:45.440
これから音声合成パイプラインを使って､ どのモデルが欲しいか指示します｡

11:45.470 --> 11:49.040
マイクロソフトのSpeech five TTSが欲しい｡ 

11:49.040 --> 11:56.900
モデルにはもう少し､ 音声の種類を設定する必要があります｡

11:56.900 --> 12:01.340
そして､ ハギング・フェイスのデータセットをロードするための行がいくつかある｡ 

12:01.490 --> 12:04.460
そして､ 正しい形に整えるんだ｡ 

12:04.460 --> 12:10.270
でも､ それができたら､ パイプラインに電話して､ 人工知能エンジニアに挨拶して､

12:10.270 --> 12:17.140
このスピーチ音声でマスターとパスへの道を歩むことになるんだ｡

12:17.410 --> 12:24.460
これは､ それをwavファイルに書き出すコードです｡ 

12:24.820 --> 12:34.360
そうすれば､ このColabノートブックの中で再生できるようになる｡ 

12:34.360 --> 12:36.220
だからかなり速く走れた｡ 

12:36.220 --> 12:38.050
どう聞こえるか見てみよう｡ 

12:38.050 --> 12:38.830
こんにちは｡ 

12:38.860 --> 12:43.450
マスターへの道を歩む人工知能エンジニアへ｡ 

12:44.200 --> 12:45.520
私にはかなりいいように思える｡ 

12:45.520 --> 12:50.590
これは音声合成にパイプラインを使う例だろう｡ 

12:50.800 --> 12:55.180
パイプラインAPIのウォークスルーはこれで終わりです｡ 

12:55.180 --> 13:00.910
もちろん､ 私はこのコラボを共有し､ みなさんがこのコラボにアクセスできるようにします｡ そして､ みなさん自身がこのコラボにアクセスし､

13:00.910 --> 13:09.880
さまざまなインプットを試し､ Huggingfaceのハブにあるさまざまなモデルを試してみることを強くお勧めします｡

13:10.180 --> 13:10.990
楽しもう｡ 
