WEBVTT

00:00.560 --> 00:04.880
私の伝統的な機械学習への進出に付き合ってくれてありがとう｡ 

00:04.880 --> 00:08.990
僕らにとっては有益だったと思うし､ 君があまり気にしなかったことを願うよ｡ 

00:09.020 --> 00:14.330
もしかしたら､ 私のように少し楽しんで､ 自分のモデルも試してみたかもしれない｡ 

00:14.360 --> 00:17.690
並べてどのように見えるかを見てみよう｡ 

00:17.690 --> 00:27.320
私たちはまず､ 無作為に選んだモデルからスタートした｡ 

00:27.320 --> 00:34.220
その後､ 一定のモデルを試したが､ それでも146ドルの間違いだった｡ 

00:34.520 --> 00:40.520
そして､ 特徴量と線形回帰モデルという適切なモデルを作成した｡ 

00:40.550 --> 00:49.370
139ドルでは､ バッグ・オブ・ワードのモデル､ カウントベクトライザーと114ドルの方が全然良かった｡ 

00:50.150 --> 00:56.570
パワフルな2ヴェクという言葉を重ねると､ 115ドルになるのが少し残念だった｡ 

00:56.570 --> 01:02.480
単語2vecの次元が400であるのに対して､ bag of

01:02.480 --> 01:09.490
wordsモデルには1000の次元があることにお気づきだろうか｡

01:09.520 --> 01:14.830
それらのベクトルにはより多くの信号があり､ より良い結果が期待できるだろう｡ 

01:14.830 --> 01:18.070
少し残念だったが､ すぐに挽回した｡ 

01:18.100 --> 01:24.700
まず最初に､ サポートベクターマシンを使うと少し良くなるが､ その後､

01:24.700 --> 01:29.980
ランダムフォレストが97ドルの誤差で窮地を脱する｡

01:29.980 --> 01:35.410
そして､ 97ドルという価格は､ 製品の価格を予測することを考えると､

01:35.410 --> 01:40.510
まだ期待外れだと言う考え方もある｡

01:40.510 --> 01:41.920
でも､ 言っておくよ｡ 

01:41.920 --> 01:47.860
私は､ あなた自身がそのような商品をいくつか選び､ やみくもに値段を付けてみることに挑戦したい｡ 

01:47.860 --> 01:49.120
簡単なことじゃない｡ 

01:49.120 --> 01:50.890
意外と難しいんだ｡ 

01:50.890 --> 01:55.360
あのLEDライトに直面したとき､ さっきの例を見ていただいたと思うのですが､

01:55.390 --> 02:00.820
もし私があれを見ていたら､ おそらく40ドルかそこらだと推測していたと思います｡

02:00.820 --> 02:02.500
しかも200ドルとかだった｡ 

02:02.500 --> 02:09.270
だから､ 何かについて説明されただけで､ それを理解するのは意外と難しいんだ｡ 

02:09.270 --> 02:11.160
これはどこのスケールですか？

02:11.250 --> 02:19.320
そして､ 電子機器かもしれないし､ 電化製品かもしれないし､ 自動車かもしれないし､

02:19.350 --> 02:28.290
もちろん､ 私たちが選んだ他のカテゴリーかもしれない｡

02:28.290 --> 02:35.610
だから､ テストセット全体で平均97ドル以内に収まるのは､ まったく悪くない｡ 

02:35.610 --> 02:36.810
全然悪くないよ｡ 

02:36.840 --> 02:39.210
でも､ もっとうまくやれる可能性はある｡ 

02:39.210 --> 02:40.320
いずれわかるだろう｡ 

02:40.590 --> 02:41.550
分かった｡ 

02:41.550 --> 02:44.520
よくぞここまでたどり着いた｡ 

02:44.520 --> 02:46.590
僕にとってはとても楽しいことだった｡ 

02:46.590 --> 02:47.220
とにかくだ｡ 

02:47.520 --> 02:51.660
あなたは私を大目に見てくれたし､ 気にならなかったと思う｡ 

02:51.720 --> 02:57.330
しかし､ 恐れることはない｡ フロンティアに行く時が来たのだ｡ 

02:57.330 --> 03:04.980
だから､ 次回はフロンティアモデルを使って商業的な問題を解決することについて話をするつもりだが､

03:04.980 --> 03:12.430
その時はGPTの4つのミニに対してそのランナーを走らせ､ その結果を見るつもりだ｡

03:12.460 --> 03:14.140
そして勇気を出す｡ 

03:14.170 --> 03:21.040
目標を高く設定し､ テストデータセットを大物､ GPT four zero maxi､

03:21.040 --> 03:27.610
フルバージョン､ 8月のフロンティアバージョンに対して実行するつもりだ｡

03:27.820 --> 03:30.790
そして､ それは我々にとって大きな試練となるだろう｡ 

03:30.790 --> 03:32.080
どうなるか見てみよう｡ 

03:32.380 --> 03:40.060
LLMは､ 基本的にトレーニングデータを与えないから､ かなり難しいんだ｡

03:40.090 --> 03:45.130
トレーニングデータを与える従来のモデルとは異なり､ 私たちは単純にテストデータをLLMに送り､

03:45.130 --> 03:53.980
あなたの世俗的な知識をすべて考慮した上で､ これはいくらになりそうで､ いくらの価値があると思いますか？

03:53.980 --> 03:56.470
そして､ それは簡単な問題ではない｡ 

03:56.470 --> 04:03.190
つまり､ 従来の機械学習モデルには､ 訓練データセットに基づいて訓練されているという大きな利点があるのだ｡

04:03.190 --> 04:08.320
これらのフロンティアモデルの場合､ 我々はただ説明を与え､ よし､ これはいくらだ､

04:08.320 --> 04:09.460
と言うだけだ｡

04:09.910 --> 04:13.120
彼らの様子は次のビデオで見てみよう｡ 
