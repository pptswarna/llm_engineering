WEBVTT

00:00.500 --> 00:05.960
이론은 너무 많다는 걸 깨달았지만 좋은 직감을 얻었길 바라요 그게 우리가

00:05.960 --> 00:08.030
하려는 일의 토대니까요

00:08.120 --> 00:14.660
또 문제가 생겼을 때 매우 도움이 됩니다 hyperperameter나 최적화를

00:14.660 --> 00:20.420
탐색할 때 왜 우리가 무엇이고 무엇을 나타내는지 알 수 있죠

00:20.420 --> 00:26.690
요약하자면 우리가 처음 시작했을 때 얘기했던 건 람다 3의 가장 작은 변종이었죠 1은 80억 매개

00:26.690 --> 00:33.770
변수 모델로 램 32GB를 차지하죠

00:33.770 --> 00:39.860
수량화해서 8비트로 만들고 9기가바이트만 사용하면 된다는

00:39.860 --> 00:41.720
걸 알게 됐죠

00:41.780 --> 00:44.480
여전히 램의 양이 많은 거죠

00:44.630 --> 00:50.090
퀀타이즈해서 비율을 4까지 낮출 수 있어요 더블 퀀트 트릭을 써서 5로

00:50.090 --> 00:52.880
낮추는 거죠 6GB요

00:52.940 --> 01:00.560
그리고 또 하나 깨달은 건 키 큰 사람을 훈련하는 대신 로라 매트릭스를

01:00.620 --> 01:08.150
미세 조정할 수 있다는 거예요 키 큰 모델에게 적용되는 거죠

01:08.150 --> 01:17.450
그렇게 되면 100MB나 109MB 매개 변수가 생기는 거죠 거대한 베이스

01:17.450 --> 01:21.680
모델에 비하면 훨씬 적은 숫자예요

01:21.680 --> 01:26.090
어떻게 짜맞추는지 감이 잘 잡히길 바라요

01:26.090 --> 01:30.620
그것과 함께 필수 도메인 전문 지식을 구축했죠

01:30.680 --> 01:34.550
이번 주는 지식을 쌓는 중요한 한 주였어요

01:34.610 --> 01:37.100
이제 모든 걸 실천할 거예요 Put it up Put it up Put it up Put it up Put it up Put it

01:37.100 --> 01:41.330
미세 조정을 위해 사용할 오픈 소스 모델을 선택할게요

01:41.330 --> 01:46.880
다양한 변형을 살펴보고 성능을 평가하기 위해 새로운 기본 모델을

01:46.910 --> 01:48.560
살펴볼 거예요

01:48.560 --> 01:52.520
다음 주는 실전일 거예요 정말 기대돼요
