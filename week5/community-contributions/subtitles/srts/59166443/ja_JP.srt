WEBVTT

00:00.590 --> 00:02.720
そしてみんな､ おかえりなさい｡ 

00:02.720 --> 00:06.200
第2週3日目へようこそ｡ 

00:06.230 --> 00:14.030
ラジオを楽しむこと､ ラジオとユーザー・インターフェースのすべてを称えることの継続だ｡

00:14.330 --> 00:22.130
オープンAI､ anthropic､ Geminiを使うだけでなく､ ソリューションのUIを構築することもできます｡

00:22.130 --> 00:24.500
そして､ それについてかなり良い気分になっているはずだ｡ 

00:24.530 --> 00:27.230
ええと､ 今日が終われば､ もっとできるようになるよ｡ 

00:27.260 --> 00:32.120
非常に一般的なUIの一種であるチャットUIを構築できるようになる｡ 

00:32.120 --> 00:38.270
会話の履歴をプロンプトで提供できるようになり､ まさに最初のカスタマー・サポート・アシスタント､

00:38.270 --> 00:42.980
AIアシスタント（チャットボットとも呼ばれる）を構築することになる｡

00:43.010 --> 00:46.280
非常に一般的な使用例だ｡ 

00:46.280 --> 00:48.590
今日でマスターできるだろう｡ 

00:49.340 --> 00:51.950
だから､ これもよくあることだ｡ 

00:51.950 --> 00:53.150
ユースケースです｡ 

00:53.150 --> 00:55.220
みんなよく知っていると思う｡ 

00:55.250 --> 00:56.810
チャットボットに基づくLlms｡ 

00:56.810 --> 00:59.210
会話に超効果的｡ 

00:59.210 --> 01:05.780
ほんの数年前まで､ ウェブサイトでこうしたチャットボット・スタイルのインターフェイスを体験すると､

01:05.780 --> 01:15.820
さまざまなことに1つ､ 2つ､ 3つ､ 4つと反応したり､ 予約などのキーワードを使ったりする世界だったことを思い出すのは難しい｡

01:15.850 --> 01:17.860
我々はここまで来た｡ 

01:17.860 --> 01:24.280
ウェブサイト上のカスタマーサービス・チャットボットと､ 十分な情報を得た上で会話をすることができるようになった｡

01:24.280 --> 01:36.460
そして､ 正直なところ､ 人間との会話よりもチャットボットとの会話から得た価値の方が大きかったこともある｡

01:36.640 --> 01:42.040
でも､ Aという文字がその文中に何回出てくるか､ というようなことは明らかにできない｡ 

01:42.400 --> 01:46.510
ええと､ とにかく､ ええと､ チャットボットの使用例です｡ 

01:46.510 --> 01:49.030
とても身近で､ とても重要なことだ｡ 

01:49.030 --> 01:51.280
そしてllmsが得意とすること｡ 

01:51.430 --> 01:57.190
チャットボットに与えることができるフレンドリーなペルソナ､

01:57.220 --> 02:11.440
あるいはどんなペルソナでも､ メッセージ間の文脈を維持する能力を持つことができます｡

02:11.440 --> 02:15.790
そして私たちは今､ それが何らかの､ 何らかの､ 何らかの策略であることを知っている｡ 

02:15.790 --> 02:19.870
本当にしつこく会話しているかのような錯覚に陥る｡ 

02:19.900 --> 02:22.500
それぞれのステップで何が起きているのか｡ 

02:22.500 --> 02:29.280
次の返答を得るために､ 会話履歴はすべてLLMに提供される｡ 

02:29.520 --> 02:37.830
それから､ アシスタントは専門的な知識を持っていて､ その知識を使って質問に答えることもできる｡

02:38.730 --> 02:45.480
だから､ アシスタントと接する上でとても重要なのは､ プロンプトを正しく使うことなんだ｡ 

02:45.480 --> 02:49.590
私たちは､ 会話のトーンを設定するために使用できるシステム・プロンプトを熟知している｡ 

02:49.590 --> 02:51.180
基本的なルールを設けることができる｡ 

02:51.180 --> 02:56.400
答えがわからなければそう言えばいい､ というよくあるプロンプトのテクニックがある｡ 

02:56.400 --> 03:01.140
幻覚を見ないよう､ llmsに真実を話すよう促すためだ｡ 

03:01.470 --> 03:09.690
コンテクストとは､ LLMが議論していることについてより多くのコンテクストを与えるために､

03:09.690 --> 03:13.140
会話に追加情報を加えることです｡

03:13.140 --> 03:21.660
そしてマルチ・ショット・プロンプトとは､ プロンプトに情報を追加して複数の交流例を示すことで､

03:21.660 --> 03:35.390
LLMの性格に磨きをかけるとともに､ 後で役に立つ情報を与えるためのものだ｡

03:35.420 --> 03:43.340
これは複数の例から学習しているため､ トレーニングのように感じられるのが面白いところだが､ もちろんこれはデータサイエンスの意味でのトレーニングではない｡

03:43.340 --> 03:45.410
モデルはすでに訓練されている｡ 

03:45.440 --> 03:47.750
ニューラルネットワークのトレーニングが行われた｡ 

03:47.780 --> 03:51.260
これはすべて､ 実行時の推論時間と呼ばれるものだ｡ 

03:51.260 --> 03:54.770
すべては過去に基づいて未来のトークンを生成しているだけなのだ｡ 

03:54.770 --> 04:01.940
しかし､ 重要なのは､ もし過去のトークンのセットに質問と答えがたくさん含まれていれば､

04:01.940 --> 04:10.610
未来を予測するときに､ 過去に見たものと一致する未来のトークンを選ぶ可能性が高くなるということだ｡

04:10.610 --> 04:13.670
だからこそ､ これはとても効果的なのだ｡ 

04:14.540 --> 04:16.700
だから､ これからチャットボットを作るんだ｡ 

04:16.730 --> 04:17.390
私たちの最初のチャットボット｡ 

04:17.390 --> 04:18.410
そして､ このようになるだろう｡ 

04:18.440 --> 04:29.690
このレッスンでは､ インスタントメッセージのようなインターフェイスで､

04:29.720 --> 04:39.020
私たちからの質問とチャットボットからの応答が行われます｡

04:39.020 --> 04:42.950
それでは早速､ JupyterLabに行ってみよう｡ 
